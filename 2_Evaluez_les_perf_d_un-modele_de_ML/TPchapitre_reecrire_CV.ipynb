{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "graphic-netscape",
   "metadata": {},
   "source": [
    "# TP Chapitre - Entraînez-vous : implémentez une validation croisée\n",
    "\n",
    "This the notebook where I constructed the method, step by step, so there are probably repeated parts of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adopted-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"~/Documents/openclassroom/Fomation_ingenieur_ML/data/\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## sklearn module : \n",
    "from sklearn import model_selection \n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ranking-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+'winequality-red+.csv', sep=\";\")\n",
    "\n",
    "## DESIGN AND SAMPLING : \n",
    "X = df.drop(\"quality\", axis = 1, inplace = False)\n",
    "threshold = np.floor(df.quality.mean())\n",
    "y = np.where(df.quality < threshold, 0,1) \n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "#### comment je créée mes conteneurs pour extraire les données train/test ?\n",
    "## PAR UN DICT GLOBAL ?\n",
    "# original_data_split={\"X_train\":X_train,\"X_test\":X_test,\n",
    "#                      \"y_train\":y_train, \"y_test\":y_test}\n",
    "# original_data_split[\"X_train\"]\n",
    "\n",
    "# class DataSplit:\n",
    "#    def __init__(self):\n",
    "#     X_train = self.X_train\n",
    "#     y_train = self.y_train\n",
    "#     X_test = self.X_test\n",
    "#     y_test = self.y_test\n",
    "    \n",
    "    \n",
    "## EXTRACT X_train, X_test FROM X AND train_index :    \n",
    "def extract_Xsplitted_data(X, train_index):    \n",
    "#     train_index = X_train.index\n",
    "    test_index = [(index not in train_index) for index in X.index]\n",
    "    X_train = X.loc[train_index]\n",
    "    X_test = X.loc[test_index]\n",
    "    return(X_train, X_test)\n",
    "\n",
    "## STANDARDIZATION : \n",
    "def normalize_from_split(X, train_index):\n",
    "    X_train, X_test = extract_Xsplitted_data(X, train_index)\n",
    "    \n",
    "    my_normalizer = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train_std = pd.DataFrame(my_normalizer.transform(X_train), index = X_train.index, columns = X_train.columns)\n",
    "    X_test_std = pd.DataFrame(my_normalizer.transform(X_test), index = X_test.index, columns = X_test.columns)\n",
    "\n",
    "    return(X_train_std, X_test_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-grain",
   "metadata": {},
   "source": [
    "###### LIST OF ARGUMENTS AT THE END \n",
    "clf_meth = neighbors.KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\"n_neighbors\" : np.arange(2,15,1)}\n",
    "\n",
    "cv = 5\n",
    "\n",
    "###### WHAT IT DOES : \n",
    "1. Create \"cv\"(=5 for ex) folds \n",
    "    \n",
    "    1.1 Separate the observations in 5 parts that respect the global distrib (folds)\n",
    "\n",
    "    1.2 Loop for fold_f in 1:5, \n",
    "            fit the clf_meth model on the Xcv_train = X_train[all fold - fold_f],\n",
    "    \n",
    "            loop for params in param_grid.keys() : \n",
    "            \n",
    "                fit clf_meth(Xcv_train, ycv_train\n",
    "            \n",
    "            save results for prediction on Xcv_test = X_train[fold_f] \n",
    "\n",
    "2. define class methods : \n",
    "    \n",
    "    2.1 cv_results_ : save mean results of models in the dict param_grid.key()\n",
    "    \n",
    "    2.2 best_params_ : the better parameter set in param_grid, in term of accuracy\n",
    "    ... many other methods, see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-gospel",
   "metadata": {},
   "source": [
    "## 1. With the Kflod function in scikit-learn :\n",
    "In the chapter \"Mettez en place un cadre de validation croisée\", they explain all the approach of the Cross Validation, from the separation in kflod, with the \"same\" classification distribution (using sklearn.model_selection.KFold or sklearn.model_selection.StratifiedKFold). So, let's first implement the second part, that is where the hyperparameters are fitted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "caring-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DESIGN AND SAMPLING : \n",
    "X = df.drop(\"quality\", axis = 1, inplace = False)\n",
    "threshold = np.floor(df.quality.mean())\n",
    "y = np.where(df.quality < threshold, 0,1) \n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "##TODO : attention, ici le X_train devient le \"X\" pour la CV \n",
    "CV_X = X_train\n",
    "CV_y = y_train \n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "# kf.get_n_splits(argX)\n",
    "\n",
    "for train_range_index, test_range_index in kf.split(CV_X) : \n",
    "#     print(\"TRAIN:\", CV_train_index, \"TEST:\", CV_test_index)\n",
    "    train_index = CV_X.index[train_range_index]\n",
    "#     test_index = CV_X.index[test_range_index] \n",
    "#     CV_X_train, CV_X_test = CV_X.loc[train_index], CV_X.loc[test_index]\n",
    "#     CV_y_train, CV_y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    ## NORMALIZE :\n",
    "    CV_X_train, CV_X_test = normalize_from_split(CV_X, train_index)\n",
    "    \n",
    "    ## FIT KNN on X_train AND PREDICT ON X_test :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "sunrise-place",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 120, 1482,  211,  879,  609, 1528,  864,  251,  378,  442,\n",
       "            ...\n",
       "             681, 1389, 1488, 1049, 1330,  854, 1133,  398,  602, 1132],\n",
       "           dtype='int64', length=896)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = CV_X\n",
    "\n",
    "CV_X.index[train_range_index]\n",
    "# X_train, X_test = extract_Xsplitted_data(X, train_index)\n",
    "\n",
    "# my_normalizer = preprocessing.StandardScaler().fit(X_train)\n",
    "# X_train_std = pd.DataFrame(my_normalizer.transform(X_train), index = X_train.index, columns = X_train.columns)\n",
    "# X_test_std = pd.DataFrame(my_normalizer.transform(X_test), index = X_test.index, columns = X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "representative-manner",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([  3,   5,  10,  13,  14,\\n            ...\\n            888, 889, 891, 892, 894],\\n           dtype='int64', length=278). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-992a4b84d741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Applications/python/conda/envs/openclassroom/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    887\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/python/conda/envs/openclassroom/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0;31m# ugly hack for GH #836\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take_opportunity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/python/conda/envs/openclassroom/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_multi_take\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \"\"\"\n\u001b[1;32m   1018\u001b[0m         \u001b[0;31m# GH 836\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         d = {\n\u001b[0m\u001b[1;32m   1020\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/python/conda/envs/openclassroom/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;31m# GH 836\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         d = {\n\u001b[0;32m-> 1020\u001b[0;31m             \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_ORDERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         }\n",
      "\u001b[0;32m~/Applications/python/conda/envs/openclassroom/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/python/conda/envs/openclassroom/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1322\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                     \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Int64Index([  3,   5,  10,  13,  14,\\n            ...\\n            888, 889, 891, 892, 894],\\n           dtype='int64', length=278). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
     ]
    }
   ],
   "source": [
    "X_train = X.loc[train_index,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-transcription",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-preliminary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-swimming",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-breath",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "heavy-hundred",
   "metadata": {},
   "source": [
    "Then I went to see the scikit-learn class defined for cross validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseCrossValidator(metaclass=ABCMeta):\n",
    "    \"\"\"Base class for all cross-validators\n",
    "    Implementations must define `_iter_test_masks` or `_iter_test_indices`.\n",
    "    \"\"\"\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            The target variable for supervised learning problems.\n",
    "        groups : array-like of shape (n_samples,), default=None\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        indices = np.arange(_num_samples(X))\n",
    "        for test_index in self._iter_test_masks(X, y, groups):\n",
    "            train_index = indices[np.logical_not(test_index)]\n",
    "            test_index = indices[test_index]\n",
    "            yield train_index, test_index\n",
    "\n",
    "    # Since subclasses must implement either _iter_test_masks or\n",
    "    # _iter_test_indices, neither can be abstract.\n",
    "    def _iter_test_masks(self, X=None, y=None, groups=None):\n",
    "        \"\"\"Generates boolean masks corresponding to test sets.\n",
    "        By default, delegates to _iter_test_indices(X, y, groups)\n",
    "        \"\"\"\n",
    "        for test_index in self._iter_test_indices(X, y, groups):\n",
    "            test_mask = np.zeros(_num_samples(X), dtype=bool)\n",
    "            test_mask[test_index] = True\n",
    "            yield test_mask\n",
    "\n",
    "    def _iter_test_indices(self, X=None, y=None, groups=None):\n",
    "        \"\"\"Generates integer indices corresponding to test sets.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        \"\"\"Returns the number of splitting iterations in the cross-validator\"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return _build_repr(self)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
