{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6450e1ae",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "I choose the simplest application with the nutriscore : Predict it for non-label aliments. My main question will be about the robustess of my missing data inference. I read about this score [on this official document](https://www.santepubliquefrance.fr/media/files/02-determinants-de-sante/nutrition-et-activite-physique/nutri-score/qr-scientifique-technique) (on \"sante public france\" [website](https://www.santepubliquefrance.fr/determinants-de-sante/nutrition-et-activite-physique/articles/nutri-score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb358f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/clairegayral/Documents/openclassroom/data/\"\n",
    "\n",
    "# On importe les librairies dont on aura besoin pour ce tp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "## plot : \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = [15, 5]\n",
    "import seaborn as sns\n",
    "## stat / model : \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import itertools as IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fefa033",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path+\"projet2/cleanned_dataframe.csv\",  index_col =0)\n",
    "data_std = pd.read_csv(data_path+\"projet2/cleanned_std_dataframe.csv\",  index_col =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b19a26e",
   "metadata": {},
   "source": [
    "# 1. Nutri-score analysis : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed16936",
   "metadata": {},
   "source": [
    "# 1.1 Univariate analysis : Nutri-score as a numerical variable\n",
    "\n",
    "Let's first see the description statistics on the variable : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0065c2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9969.000000\n",
       "mean        9.115558\n",
       "std         8.883424\n",
       "min       -14.000000\n",
       "25%         1.000000\n",
       "50%        10.000000\n",
       "75%        16.000000\n",
       "max        37.000000\n",
       "Name: nutrition-score-fr_100g, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[\"nutrition-score-fr_100g\"].copy()\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52a04e",
   "metadata": {
    "variables": {
     "max(y)": "37.0",
     "min(y)": "-13.999999999999998",
     "y.mean()": "9.115558230514596",
     "y.quantile(0.5)": "10.0"
    }
   },
   "source": [
    "So it takes values between {{min(y)}} and {{max(y)}}, it is well-centered : the mean (={{y.mean()}}) is close to the median value (={{y.quantile(0.5)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f7b992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'nutrition-score')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_bins = len(np.unique(y.dropna().values))\n",
    "plt.hist(y, bins = nb_bins, color='steelblue', density=True, edgecolor='none')\n",
    "plt.title(\"nutrition-score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ceb1b",
   "metadata": {},
   "source": [
    "This varible as both negative and positive values, but I still look at the Lorenz curve and AUC, after rescaling y with a min-translatation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07212472",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lorenz curve : \n",
    "import numpy as np\n",
    "\n",
    "n = len(y)\n",
    "y_rescaled = y - min(y)\n",
    "lorenz = np.cumsum(np.sort(y_rescaled)) / y_rescaled.sum()\n",
    "lorenz = np.append([0],lorenz) # La courbe de Lorenz commence à 0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.axis('scaled')\n",
    "xaxis = np.linspace(0-1/n,1+1/n,n+1) \n",
    "plt.plot(xaxis,lorenz,drawstyle='steps-post')\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.plot([0,0],[-0.1,1.1], color=\"grey\") # y axis \n",
    "plt.plot([-0.1,1.1],[0,0], color=\"grey\") # x axis\n",
    "\n",
    "plt.show()\n",
    "\n",
    "AUC = (lorenz.sum() -lorenz[-1]/2 -lorenz[0]/2)/n # Surface sous la courbe de Lorenz. Le premier segment (lorenz[0]) est à moitié en dessous de 0, on le coupe donc en 2, on fait de même pour le dernier segment lorenz[-1] qui est à moitié au dessus de 1.\n",
    "S = 0.5 - AUC # surface entre la première bissectrice et le courbe de Lorenz\n",
    "gini = 2*S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263ffbb",
   "metadata": {
    "variables": {
     "np.round(AUC,2)": {},
     "np.round(gini,2)": {}
    }
   },
   "source": [
    "The AUC is {{np.round(AUC,2)}}, that means that ... .\n",
    "Futhermore, the gini indice is {{np.round(gini,2)}}\n",
    "\n",
    "**write the interpretation + solve affichage variable in markedown**\n",
    "https://openclassrooms.com/fr/courses/4525266-decrivez-et-nettoyez-votre-jeu-de-donnees/4730366-familiarisez-vous-avec-les-mesures-de-concentration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6237df04",
   "metadata": {},
   "source": [
    "## 1.2 Qualitative data analysis : Transform score into letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d353dee6",
   "metadata": {},
   "source": [
    "Now, the document allow us to transform this score variable into the corresponding score letter : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97616d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(columns = [\"score\",\"min_liquide\",\"max_liquide\",\"min_solide\",\"max_solide\"])\n",
    "tmp[\"score\"] = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "tmp[\"min_liquide\"] = [np.nan,-100,2,6,10]\n",
    "tmp[\"max_liquide\"] = [np.nan, 1, 5, 9, 100]\n",
    "tmp[\"min_solide\"] = [-100,0,3,11,19]\n",
    "tmp[\"max_solide\"] = [-1,2,10,18,100]\n",
    "tmp.score = tmp.score.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce58cf",
   "metadata": {},
   "source": [
    "As the nature (liquide or solid) of the product is a main element to determine that score, it would be better to **find a way to classify liquid and solid products**\n",
    "I think that is a property we may deduce from the text description variable, and I do not have the time for this project to go that far. So I'll just compute the letter corresponding to solid scores, as an approximation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_score_letter(product_score):\n",
    "    ref_max = pd.Series([-1,2,10,18,100], \n",
    "                        index=[\"A\", \"B\", \"C\", \"D\", \"E\"],\n",
    "                        dtype = \"float\")\n",
    "    return(ref_max[(product_score <= ref_max)].index[0])\n",
    "\n",
    "letter_score = [transform_score_letter(y.iloc[i]) for i in range(len(y))]\n",
    "letter_score = pd.Series(letter_score, dtype=\"category\", index = y.index, name=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_count = letter_score.value_counts()/letter_score.count()\n",
    "labels = ['A', 'B', 'C', 'D', 'E']\n",
    "plt.bar(labels, letter_count[labels])\n",
    "plt.title(\"Barplot of the letter score\")\n",
    "plt.ylabel(\"proportion of products\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(letter_count[labels], #explode=0.1*np.ones(len(labels)),\n",
    "        labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58aceef",
   "metadata": {},
   "source": [
    "Let's integrate this categorical information to our numerical data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ee228",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "description_var = ['code', 'countries', 'creator', 'product_name']\n",
    "float_var = ['additives_n', 'ingredients_from_palm_oil', 'energy-kcal_100g',\n",
    "             'energy_100g', 'fat_100g', 'saturated-fat_100g', 'trans-fat_100g',\n",
    "             'cholesterol_100g', 'carbohydrates_100g', 'sugars_100g',\n",
    "             'fiber_100g', 'proteins_100g', 'sodium_100g', 'vitamin-a_100g',\n",
    "             'vitamin-c_100g', 'calcium_100g', 'iron_100g',\n",
    "             'nutrition-score-fr_100g']\n",
    "data2 = pd.concat([letter_score, data[data.columns.intersection(float_var)]], axis = 1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bins = len(np.unique(y.dropna().values))\n",
    "my_color_set = ['#154406', '#15b01a', '#ffdf22', '#f97306', '#c0022f',\n",
    "                '#0343df', '#fe02a2', '#8b3103', '#7e1e9c', '#017371',\n",
    "                '#380282', '#6b8ba4', '#75bbfd', '#ff81c0', '#c79fef',\n",
    "                '#ff073a', '#fdaa48', '#fea993', '#fe7b7c', '#c20078',\n",
    "                '#029386', '#677a04', '#b25f03', '#070d0d', '#ffdf22']\n",
    "N, bins, patches = plt.hist(data2[\"nutrition-score-fr_100g\"], bins = nb_bins, density=True, edgecolor='white')\n",
    "\n",
    "## add coloration on histogram : \n",
    "limit_bins = [-1,2,10,18, data2[\"nutrition-score-fr_100g\"].max()] - data2[\"nutrition-score-fr_100g\"].min()\n",
    "my_min = 0\n",
    "k = 0\n",
    "for my_max in limit_bins :\n",
    "    my_max = int(my_max - 1) \n",
    "    for i in range(my_min,my_max):\n",
    "        patches[i].set_facecolor(my_color_set[k])\n",
    "    my_min = my_max\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5141c0e0",
   "metadata": {},
   "source": [
    "# 2. Multivariate Analysis  \n",
    "## 2.1 Correlation Matrix :\n",
    "Let us first of all see if the variable are correlated : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc1bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_heatmap(corr): \n",
    "    ax = sns.heatmap(\n",
    "        corr, \n",
    "        vmin=-1, vmax=1, center=0,\n",
    "        cmap=sns.diverging_palette(20, 220, n=200),\n",
    "        square=True\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        ax.get_xticklabels(),\n",
    "        rotation=45,\n",
    "        horizontalalignment='right'\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255393aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data2.corr()\n",
    "plot_corr_heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df34562",
   "metadata": {},
   "source": [
    "Let's sort the correlation index by the values in the nutrition score : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9555af7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_corr = corr.sort_values(by=\"nutrition-score-fr_100g\", ascending = True)\n",
    "sorted_corr = sorted_corr.sort_values(by=\"nutrition-score-fr_100g\", axis = 1, ascending = True)\n",
    "plot_corr_heatmap(sorted_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee055525",
   "metadata": {},
   "source": [
    "There seems to be a cluster of correlated variable conserning fat and energy, and the other variables does not seem so correlated. \n",
    "\n",
    "## 2.2 Dimension Reduction with PCA : \n",
    "\n",
    "If it's the case, computing a PCA. \n",
    "Note that most of this code is an adapation of [the TP code proposed in the OC class](https://openclassrooms.com/fr/courses/4525281-realisez-une-analyse-exploratoire-de-donnees/5345201-tp-realisez-une-acp). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# choix du nombre de composantes à calculer\n",
    "n_comp = 6\n",
    "\n",
    "# selection des colonnes à prendre en compte dans l'ACP\n",
    "X = data2.drop([\"score\",\"nutrition-score-fr_100g\"],axis = 1, inplace = False)\n",
    "\n",
    "# préparation des données pour l'ACP\n",
    "scores = np.intc(data2[\"nutrition-score-fr_100g\"]) # ou data.index pour avoir les intitulés\n",
    "features = data2.columns\n",
    "\n",
    "# Centrage et Réduction\n",
    "std_scale = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = std_scale.transform(X)\n",
    "\n",
    "# Calcul des composantes principales\n",
    "pca = decomposition.PCA(n_components=n_comp)\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c4e3f",
   "metadata": {},
   "source": [
    "Let's see the explained variance each new component brings : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eboulis des valeurs propres\n",
    "display_scree_plot(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed501ca",
   "metadata": {},
   "source": [
    "The first axe explaines 20% of the variance, and the second 12.5%. That is really low, I think that it's relevant to use our knowlegde about the cluster of \"fat\" variables to gather them before doing the global pca. \n",
    "\n",
    "### 2.2.1. Focus on PCA variables : \n",
    "\n",
    "To be sure, let's see the correlation circle and the projected cloud of the products in the two firsts axis :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a00a301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cercle des corrélations\n",
    "pcs = pca.components_\n",
    "display_circles(pcs, 2, pca, [(0,1)], labels = np.array(features))\n",
    "\n",
    "# Projection des individus\n",
    "X_projected = pca.transform(X_scaled)\n",
    "X_projected = pd.DataFrame(X_projected, index = X.index, \n",
    "                           columns = [\"Axis\"+ str(k) for k in np.arange(1,X_projected.shape[1]+1)])\n",
    "\n",
    "display_factorial_planes(X_projected, 2, pca, [(0,1)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcs = pd.DataFrame(pcs, index = [\"Axis\"+ str(k) for k in np.arange(1,n_comp+1)],\n",
    "#              columns=X.columns)\n",
    "# X_projected = pd.DataFrame(X_projected, index = X.index, columns = [\"Axis\"+ str(k) for k in np.arange(1,n_comp+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec1556c",
   "metadata": {},
   "source": [
    "It is hard to distinguish the too close variables. I go back to my idea of a hierarchical clustering on variables to first gather the ones with same comportement. Same as before, I mostly adapt the code from [the corresponding OC course](https://openclassrooms.com/fr/courses/4525281-realisez-une-analyse-exploratoire-de-donnees/5345241-tp-partitionnez-vos-donnees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e768db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "# Clustering hiérarchique\n",
    "Z = linkage(X_scaled.transpose(), 'ward')\n",
    "\n",
    "# Affichage du dendrogramme\n",
    "plot_dendrogram(Z, X.columns, figsize = (15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816139f2",
   "metadata": {},
   "source": [
    "I modified the function to draw pca corr circle, so that I can put some clustering colors on the arrows, and print the corresponding legend : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e468623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str_vars(list_of_var):\n",
    "    # from a list of str, return a sentence\n",
    "    # if the line is too long (sup to 40), cut\n",
    "    tmp = list_of_var.copy()\n",
    "    res = \"\"\n",
    "    len_line = 0\n",
    "    while tmp : \n",
    "        var = tmp.pop()\n",
    "        res = res+ var +str(\", \")\n",
    "        len_line += len(var)\n",
    "        if len_line > 40:\n",
    "            res = res +\"\\n\"\n",
    "            len_line = 0\n",
    "    return(res)\n",
    "\n",
    "def draw_cluster_legend(ax2,clustering, corresp_color_dict):\n",
    "    ## plot the legend with colored arrow\n",
    "    # number of clusters : \n",
    "    K = len(clustering.values.categories)\n",
    "    my_color = clustering.values.categories.map(corresp_color_dict)\n",
    "    # plot parallel arrows :\n",
    "    ax2.quiver(np.zeros(K),np.arange(0,K),np.ones(K),np.zeros(K),\n",
    "               color = my_color)\n",
    "    # plot legend text next to the respective arrow :\n",
    "    for k in clustering.values.categories :\n",
    "        cluster_var = get_str_vars(list(clustering[clustering == k].index.values))\n",
    "        ax2.text(0.2, k , str(cluster_var), fontsize='11',\n",
    "                 ha='left', va='center' , alpha=1)\n",
    "    # set limits : \n",
    "    ax2.set_xlim([-0.1,2])\n",
    "    ax2.set_ylim([-1.1, K+0.1])\n",
    "    ax2.set_title(\"Clustering legend\")\n",
    "    # remove axis :\n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    plt.axis(\"off\")\n",
    "    return(ax2)\n",
    "\n",
    "# fig2, ax2 = plt.subplots(1,1)\n",
    "# draw_cluster_legend(ax2, cluster)\n",
    "# plt.show()\n",
    "\n",
    "def display_circles(pcs, n_comp, pca, axis_ranks, labels=None, label_rotation=0, lims=None, clustering = None):\n",
    "    ## set coloration palette : \n",
    "    if clustering is not None : \n",
    "        my_color_set = ['#154406', '#15b01a', '#f97306', '#c0022f',\n",
    "                        '#0343df', '#fe02a2', '#8b3103', '#7e1e9c', '#017371',\n",
    "                        '#380282', '#6b8ba4', '#75bbfd', '#ff81c0', '#c79fef',\n",
    "                        '#ff073a', '#fdaa48', '#fea993', '#fe7b7c', '#c20078',\n",
    "                        '#029386', '#677a04', '#b25f03', '#070d0d', '#ffdf22']\n",
    "        corresp_color_dict = dict(zip(clustering.values.categories, my_color_set))\n",
    "        my_color = clustering.values.map(corresp_color_dict)\n",
    "\n",
    "    else : \n",
    "        my_color = \"grey\"\n",
    "    ## set global plot arguments : \n",
    "    plot_kwargs = {\"alpha\":1, \"color\":my_color}\n",
    "    ## draw the correlation circle for pca : \n",
    "    for d1, d2 in axis_ranks: # On affiche les 3 premiers plans factoriels, donc les 6 premières composantes\n",
    "        if d2 < n_comp:\n",
    "            ## initialise figure\n",
    "            if clustering is not None : \n",
    "                fig = plt.figure(figsize = (18,6))\n",
    "                ## affichage de la legende du clustering en couleur : \n",
    "                ax2 = fig.add_subplot(1,2,2)\n",
    "                draw_cluster_legend(ax2, clustering, corresp_color_dict)\n",
    "                # initialisation de la figure \"cercle\"\n",
    "                ax1 = fig.add_subplot(1,2,1)\n",
    "            else : \n",
    "                fig = plt.figure(figsize = (9,6))\n",
    "                ax1 = fig.add_subplot(1,1,1)\n",
    "\n",
    "            ## détermination des limites du graphique\n",
    "            if lims is not None :\n",
    "                xmin, xmax, ymin, ymax = lims\n",
    "            elif pcs.shape[1] < 30 :\n",
    "                xmin, xmax, ymin, ymax = -1, 1, -1, 1\n",
    "            else :\n",
    "                xmin, xmax, ymin, ymax = min(pcs[d1,:]), max(pcs[d1,:]), min(pcs[d2,:]), max(pcs[d2,:])\n",
    "\n",
    "            ## affichage des fleches :\n",
    "            if pcs.shape[1] < 30 :\n",
    "                ax1.quiver(np.zeros(pcs.shape[1]), np.zeros(pcs.shape[1]), ## depart points\n",
    "                           pcs[d1,:], pcs[d2,:], ## movement in each direction\n",
    "                           angles='xy', scale_units='xy',**plot_kwargs)\n",
    "                # (voir la doc : https://matplotlib.org/api/_as_gen/matplotlib.pyplot.quiver.html)\n",
    "            else: # s'il y a plus de 30 flèches, on n'affiche pas le triangle à leur extrémité\n",
    "                lines = [[[0,0],[x,y]] for x,y in pcs[[d1,d2]].T]\n",
    "                ax1.add_collection(LineCollection(lines, axes=ax, alpha=.1, color=my_color))\n",
    "\n",
    "            ## affichage des noms des variables  \n",
    "            if labels is not None:  \n",
    "                for i,(x, y) in enumerate(pcs[[d1,d2]].T):\n",
    "                    if x >= xmin and x <= xmax and y >= ymin and y <= ymax :\n",
    "                        ax1.text(x, y, labels[i], fontsize='14', ha='center', \n",
    "                                 va='center', rotation=label_rotation, color=\"blue\", alpha=0.5)\n",
    "\n",
    "            ## affichage du cercle\n",
    "            circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "            plt.gca().add_artist(circle)\n",
    "\n",
    "            ## définition des limites du graphique\n",
    "            ax1.set_xlim(xmin, xmax)\n",
    "            ax1.set_ylim(ymin, ymax)\n",
    "\n",
    "            ## affichage des lignes horizontales et verticales\n",
    "            plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n",
    "            plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n",
    "\n",
    "            ## nom des axes, avec le pourcentage d'inertie expliqué\n",
    "            ax1.set_xlabel('F{} ({}%)'.format(d1+1, \n",
    "                                round(100*pca.explained_variance_ratio_[d1],1)))\n",
    "            ax1.set_ylabel('F{} ({}%)'.format(d2+1, \n",
    "                                round(100*pca.explained_variance_ratio_[d2],1)))\n",
    "            ax1.set_title(\"Cercle des corrélations (F{} et F{})\".format(d1+1, d2+1))\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bbbf5f",
   "metadata": {},
   "source": [
    "I let this code here as asked for the project, but I copied it in the \"functions.py\" file. Let's lauch this on our pca : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65b1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import cut_tree\n",
    "import matplotlib._color_data as mcd\n",
    "import random\n",
    "\n",
    "# clustering = pd.Series(cut_tree(Z, height=170).T[0], index=X.columns, dtype=\"category\")\n",
    "clustering = pd.Series(cut_tree(Z, n_clusters=5).T[0], index=X.columns, dtype=\"category\")\n",
    "pcs = pca.components_\n",
    "\n",
    "display_circles(pcs, 4, pca, [(0,1), (2,3)], labels = None, clustering=clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d8f2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clustering = pd.Series(cut_tree(Z, n_clusters=8).T[0], index=X.columns, dtype=\"category\")\n",
    "display_circles(pcs, 4, pca, [(0,1), (2,3)], labels = None, clustering=clustering)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3eb01f",
   "metadata": {},
   "source": [
    "The arrow are far away from the circle, so the variables are not weel represented in this projection. The color allow us to see that the clustering of variables is kept, while projecting on the PCA axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a8a4a",
   "metadata": {},
   "source": [
    "###  2.2.2. Focus on representation of products in pca axis : \n",
    "Now, let's focus on the projection of individuals onto the pca axis. In the same way, I wan to be able to put a clustering/a coloration on this plot. In deed, it would be a good way to see if in this projection, the nutri-score is well separated (it may not be at all, seeing the correlation heatmap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa9898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_projected = pca.transform(X_scaled)\n",
    "X_projected = pd.DataFrame(X_projected, index = X.index, \n",
    "                           columns = [\"Axis\"+ str(k) for k in np.arange(1,X_projected.shape[1]+1)])\n",
    "n_comp = 4\n",
    "# pca = \n",
    "axis_ranks =  [(0,1), (2,3)]\n",
    "ind_labels=None\n",
    "alpha=1\n",
    "clustering = data2[\"score\"]\n",
    "\n",
    "def display_factorial_planes(X_projected, n_comp, pca, axis_ranks, alpha=1, clustering = None):\n",
    "    # args are as defined just above \n",
    "    plot_kwargs = {\"marker\":\"x\", \"alpha\":alpha, 's':15}#, \"label\" : clustering.values.categories}\n",
    "    # set dict of color if clustering : \n",
    "    if clustering is not None : \n",
    "        ## add yellow in color to match with nutri-score : (yellow = '#ffdf22')\n",
    "        my_color_set = ['#154406', '#15b01a', '#ffdf22', '#f97306', '#c0022f',\n",
    "                        '#0343df', '#fe02a2', '#8b3103', '#7e1e9c', '#017371',\n",
    "                        '#380282', '#6b8ba4', '#75bbfd', '#ff81c0', '#c79fef',\n",
    "                        '#ff073a', '#fdaa48', '#fea993', '#fe7b7c', '#c20078',\n",
    "                        '#029386', '#677a04', '#b25f03', '#070d0d', '#ffdf22']\n",
    "        corresp_color_dict = dict(zip(clustering.values.categories, my_color_set))\n",
    "\n",
    "    for d1,d2 in axis_ranks:\n",
    "        if d2 < n_comp:\n",
    "            ax1 = \"Axis\"+ str(d1+1)\n",
    "            ax2 = \"Axis\"+ str(d2+1)\n",
    "            # initialisation de la figure       \n",
    "            fig = plt.figure(figsize=(12,10))\n",
    "            if clustering is not None :\n",
    "                for k in clustering.values.categories:\n",
    "                    cluster_index = clustering[clustering==k].index\n",
    "    #                 print(X_projected.loc[cluster_index, ax1])\n",
    "                    plt.scatter(X_projected.loc[cluster_index, ax1],X_projected.loc[cluster_index, ax2], \n",
    "                                color=corresp_color_dict[k], label = k, **plot_kwargs)\n",
    "                    plt.legend()\n",
    "\n",
    "            else : \n",
    "                plt.scatter(X_projected[ax1], X_projected[ax2], **plot_kwargs)\n",
    "            # affichage des labels des points\n",
    "            if ind_labels is not None:\n",
    "                for i,(x,y) in enumerate(X_projected[:,[d1,d2]]):\n",
    "                    plt.text(x, y, ind_labels[i],\n",
    "                              fontsize='14', ha='center',va='center') \n",
    "\n",
    "            # détermination des limites du graphique\n",
    "            boundary = np.max(np.abs(X_projected.values[:, [d1,d2]])) * 1.1\n",
    "            plt.xlim([-boundary,boundary])\n",
    "            plt.ylim([-boundary,boundary])\n",
    "\n",
    "            # affichage des lignes horizontales et verticales\n",
    "            plt.plot([-100, 100], [0, 0], color='grey', ls='--')\n",
    "            plt.plot([0, 0], [-100, 100], color='grey', ls='--')\n",
    "\n",
    "            # nom des axes, avec le pourcentage d'inertie expliqué\n",
    "            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n",
    "            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n",
    "\n",
    "            plt.title(\"Projection des individus (sur F{} et F{})\".format(d1+1, d2+1))\n",
    "            plt.show(block=False)\n",
    "display_factorial_planes(X_projected, n_comp, pca, axis_ranks, alpha=1, clustering = clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a1bb39",
   "metadata": {},
   "source": [
    "There are too many products to see anything on this plot, even when I reduce the size of the marker. To see something, let's plot score by score, on the 2 firsts axis : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_ranks =  [(0,1)]\n",
    "\n",
    "# args are as defined just above \n",
    "plot_kwargs = {\"marker\":\"x\", \"alpha\":alpha, 's':10}#, \"label\" : clustering.values.categories}\n",
    "# set dict of color if clustering : \n",
    "if clustering is not None : \n",
    "    ## add yellow in color to match with nutri-score : (yellow = '#ffdf22')\n",
    "    my_color_set = ['#154406', '#15b01a', '#ffdf22', '#f97306', '#c0022f',\n",
    "                    '#0343df', '#fe02a2', '#8b3103', '#7e1e9c', '#017371',\n",
    "                    '#380282', '#6b8ba4', '#75bbfd', '#ff81c0', '#c79fef',\n",
    "                    '#ff073a', '#fdaa48', '#fea993', '#fe7b7c', '#c20078',\n",
    "                    '#029386', '#677a04', '#b25f03', '#070d0d', '#ffdf22']\n",
    "    corresp_color_dict = dict(zip(clustering.values.categories, my_color_set))\n",
    "\n",
    "for cluster in clustering.values.categories:\n",
    "    selected_index = clustering[clustering==cluster].index\n",
    "    sub_X_projected = X_projected.loc[selected_index,:]\n",
    "    for d1,d2 in axis_ranks:\n",
    "        if d2 < n_comp:\n",
    "            ax1 = \"Axis\"+ str(d1+1)\n",
    "            ax2 = \"Axis\"+ str(d2+1)\n",
    "            # initialisation de la figure       \n",
    "            fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "            plt.scatter(sub_X_projected.loc[:, ax1],sub_X_projected.loc[:, ax2], \n",
    "                        color=corresp_color_dict[cluster], label = cluster, **plot_kwargs)\n",
    "            plt.legend()\n",
    "\n",
    "            # détermination des limites du graphique\n",
    "            boundary = np.max(np.abs(X_projected.values[:, [d1,d2]])) * 1.1\n",
    "            plt.xlim([-boundary,boundary])\n",
    "            plt.ylim([-boundary,boundary])\n",
    "\n",
    "            # affichage des lignes horizontales et verticales\n",
    "            plt.plot([-100, 100], [0, 0], color='grey', ls='--')\n",
    "            plt.plot([0, 0], [-100, 100], color='grey', ls='--')\n",
    "\n",
    "            # nom des axes, avec le pourcentage d'inertie expliqué\n",
    "            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n",
    "            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n",
    "\n",
    "            plt.title(\"Projection des individus (sur F{} et F{})\".format(d1+1, d2+1))\n",
    "            plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79129276",
   "metadata": {},
   "source": [
    "Ok, so it's still hard to see anything : \n",
    "* the variables are not that well represented with PCA \n",
    "* the scores does not seem to be well separated in the two first axis of PCA.\n",
    "\n",
    "**Improvment : first merge variables clustered by hierarchical clustering, before computing PCA**\n",
    "\n",
    "I decided to use an ANOVA to see if the correlation between the nutrition information and the letter the nutri-score is significative, projected on my pca axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fdb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pd.concat((X_projected,data2[\"score\"]),axis=1)\n",
    "X_pca.head()\n",
    "X_pca.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0828e",
   "metadata": {},
   "source": [
    "## 2.3. ANOVA \n",
    "\n",
    "So I have my different variables and my modalities, let's plot a box plot on the projected variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6197ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modality_var = \"score\"\n",
    "var = \"Axis1\"\n",
    "# data = X_pca\n",
    "\n",
    "def plot_boxplot(data,modality_var, var):\n",
    "    groupes = []\n",
    "    modalites = X_pca[modality_var].values.categories\n",
    "    for m in modalites:\n",
    "        groupes.append(data[data[\"score\"]==m][var])\n",
    "\n",
    "    # Propriétés graphiques \n",
    "    medianprops = {'color':\"black\"}\n",
    "    meanprops = {'marker':'o', 'markeredgecolor':'black','markerfacecolor':'blue'}\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(9,4))\n",
    "    # box plot : \n",
    "    boxplot = ax.boxplot(groupes, labels=modalites, showfliers=False, medianprops=medianprops, \n",
    "                vert=True, patch_artist=True, showmeans=True, meanprops=meanprops)\n",
    "    ax.set_title(str(\"Box plot \"+var))\n",
    "    # add color : \n",
    "    for patch, color in zip(boxplot['boxes'], my_color_set):\n",
    "        patch.set_facecolor(color)\n",
    "    plt.show()\n",
    "for k in range(6):\n",
    "    ax = \"Axis\"+ str(k+1)\n",
    "    plot_boxplot(X_pca,modality_var, ax) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b2f49",
   "metadata": {},
   "source": [
    "**comment box plot here**\n",
    "\n",
    "Let's look at the ANOVA :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ffd366",
   "metadata": {},
   "source": [
    "$$\\eta^2 = \\frac{\\text{Var}_{\\text{interclass}}}{\\text{Var}_{\\text{totale}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388749d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eta_squared(x,y):\n",
    "    moyenne_y = y.mean()\n",
    "    mean_by_mod = y.mean()\n",
    "    classes = []\n",
    "    for classe in x.unique():\n",
    "        yi_classe = y[x==classe]\n",
    "        classes.append({'ni': len(yi_classe),\n",
    "                        'moyenne_classe': yi_classe.mean()})\n",
    "    SCT = sum([(yj-moyenne_y)**2 for yj in y])\n",
    "    SCE = sum([c['ni']*(c['moyenne_classe']-moyenne_y)**2 for c in classes])\n",
    "    return SCE/SCT\n",
    "\n",
    "for k in range(6):\n",
    "    ax = \"Axis\"+ str(k+1)\n",
    "    print(\"eta² \", ax, \" = \",  eta_squared(X_pca[\"score\"],X_pca[ax]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454498a",
   "metadata": {},
   "source": [
    "The [OC class](https://openclassrooms.com/fr/courses/4525266-decrivez-et-nettoyez-votre-jeu-de-donnees/4774896-analysez-une-variable-quantitative-et-une-qualitative-par-anova) on that does not go father. \n",
    "\n",
    "I fisrt use this [simple tuto](http://www.python-simple.com/python-statsmodels/statsmodels-anova.php). It explains how to compute an ANOVA with the library \"statmodels\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5893f7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from scipy.stats import f_oneway\n",
    "import statsmodels.formula.api\n",
    "import statsmodels.api\n",
    "## extract data and fit model\n",
    "fit = statsmodels.formula.api.ols(\"Axis1 ~ score\", data = X_pca).fit()\n",
    "## compute ANOVA \n",
    "table = statsmodels.api.stats.anova_lm(fit)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69868c28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## correct heteroscedasticity : \n",
    "statsmodels.stats.anova.anova_lm(fit, robust = 'hc3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81572b0d",
   "metadata": {},
   "source": [
    "They use a \"turkey HSD\" : **(what is it ?) + code error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d751a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = statsmodels.stats.multicomp.pairwise_tukeyhsd(X_pca[\"score\"], X_pca[\"Axis1\"], alpha = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f21542",
   "metadata": {},
   "source": [
    "Then, I went on the [statmodels library documentation](https://www.statsmodels.org/stable/generated/statsmodels.multivariate.manova.MANOVA.html), they put a link to the [following reference](ftp://public.dhe.ibm.com/software/analytics/spss/documentation/statistics/27.0.1/en/client/Manuals/IBM_SPSS_Statistics_Base.pdf)\n",
    "\n",
    "--> **looks really cool, to read after I had a look at my stat classics**\n",
    "\n",
    "I decided to plot the pairplot on my pca axis : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d948dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Affichage des diagrammes de dispersion\n",
    "my_palette = {\"A\": '#154406', \"B\":'#15b01a', \"C\":'#ffdf22', \"D\":'#f97306', \"E\":'#c0022f'}\n",
    "# [\"Axis\"+str(k+1) for k in range(3)] + [\"score\"]\n",
    "sns.pairplot(X_pca, hue=\"score\", diag_kind=\"hist\",\n",
    "             palette=my_palette,plot_kws={\"s\": 10, \"alpha\":1})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"Axis\"+str(k+1) for k in range(3)] + [\"score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59329884",
   "metadata": {},
   "source": [
    "# 3. Linear Regression on nutri-score \n",
    "Let's see if the nutri-score can be predicted from the nutrition variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a81d4b",
   "metadata": {},
   "source": [
    "## 3.1. On PCA variable \n",
    "Let's split the standized data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DESIGN MATRICES : \n",
    "X = X_projected.copy()\n",
    "y = data[\"nutrition-score-fr_100g\"].copy()\n",
    "\n",
    "## SPLIT DATA \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from yellowbrick.datasets import load_concrete\n",
    "from yellowbrick.regressor import AlphaSelection\n",
    "\n",
    "# Load the regression dataset\n",
    "X, y = load_concrete()\n",
    "\n",
    "# Create a list of alphas to cross-validate against\n",
    "alphas = np.logspace(-10, 1, 400)\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "model = LassoCV(alphas=alphas)\n",
    "visualizer = AlphaSelection(model)\n",
    "visualizer.fit(X, y)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ae5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa23d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d63f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed838cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aee8fb19",
   "metadata": {},
   "source": [
    "**same code with the problem on legend :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_projected\n",
    "n_comp = 4\n",
    "# pca\n",
    "axis_ranks =  [(0,1), (2,3)]\n",
    "ind_labels=None\n",
    "alpha=1 \n",
    "illustrative_var=\"additive_n\"\n",
    "clustering = data[\"score\"]\n",
    "\n",
    "X_projected = pca.transform(X_scaled)\n",
    "X_projected = pd.DataFrame(X_projected, index = X.index, \n",
    "                           columns = [\"Axis\"+ str(k) for k in np.arange(1,X_projected.shape[1]+1)])\n",
    "\n",
    "def display_factorial_planes_pb_legend(X_projected, n_comp, pca, axis_ranks, ind_labels=None, alpha=1, clustering=None):\n",
    "    plot_kwargs = {\"marker\":\"x\", \"alpha\":alpha}#, \"label\" : clustering.values.categories}\n",
    "\n",
    "    if clustering is not None : \n",
    "        my_color_set = ['#154406', '#15b01a', '#f97306', '#c0022f',\n",
    "                        '#0343df', '#fe02a2', '#8b3103', '#7e1e9c', '#017371',\n",
    "                        '#380282', '#6b8ba4', '#75bbfd', '#ff81c0', '#c79fef',\n",
    "                        '#ff073a', '#fdaa48', '#fea993', '#fe7b7c', '#c20078',\n",
    "                        '#029386', '#677a04', '#b25f03', '#070d0d', '#ffdf22']\n",
    "        corresp_color_dict = dict(zip(clustering.values.categories, my_color_set))\n",
    "    #     my_color = clustering.values.map(corresp_color_dict)\n",
    "        plot_kwargs[\"color\"] = clustering.values.map(dict(zip(clustering.values.categories, my_color_set)))\n",
    "    else :\n",
    "        plot_kwargs[\"color\"] = \"grey\"\n",
    "    for d1,d2 in axis_ranks:\n",
    "        if d2 < n_comp:\n",
    "            # initialisation de la figure       \n",
    "            fig = plt.figure(figsize=(7,6))\n",
    "\n",
    "            plt.scatter(X_projected.values[:, d1], X_projected.values[:, d2], **plot_kwargs)\n",
    "            if clustering is not None :\n",
    "                plt.legend(clustering.values.categories)\n",
    "\n",
    "            # affichage des labels des points\n",
    "            if ind_labels is not None:\n",
    "                for i,(x,y) in enumerate(X_projected.values[:,[d1,d2]]):\n",
    "                    plt.text(x, y, ind_labels[i],\n",
    "                              fontsize='14', ha='center',va='center') \n",
    "\n",
    "            # détermination des limites du graphique\n",
    "            boundary = np.max(np.abs(X_projected.values[:, [d1,d2]])) * 1.1\n",
    "            plt.xlim([-boundary,boundary])\n",
    "            plt.ylim([-boundary,boundary])\n",
    "\n",
    "            # affichage des lignes horizontales et verticales\n",
    "            plt.plot([-100, 100], [0, 0], color='grey', ls='--')\n",
    "            plt.plot([0, 0], [-100, 100], color='grey', ls='--')\n",
    "\n",
    "            # nom des axes, avec le pourcentage d'inertie expliqué\n",
    "            plt.xlabel('F{} ({}%)'.format(d1+1, round(100*pca.explained_variance_ratio_[d1],1)))\n",
    "            plt.ylabel('F{} ({}%)'.format(d2+1, round(100*pca.explained_variance_ratio_[d2],1)))\n",
    "\n",
    "            plt.title(\"Projection des individus (sur F{} et F{})\".format(d1+1, d2+1))\n",
    "            plt.show(block=False)\n",
    "display_factorial_planes_pb_legend(X_projected, n_comp, pca, axis_ranks, ind_labels=None, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c309f1",
   "metadata": {},
   "source": [
    "[a source to dig](ftp://public.dhe.ibm.com/software/analytics/spss/documentation/statistics/27.0.1/fr/client/Manuals/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55186c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openclassroom",
   "language": "python",
   "name": "openclassroom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
