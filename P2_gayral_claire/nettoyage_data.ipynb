{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanning notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first call the libraries I'll use : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/clairegayral/Documents/openclassroom/data/\"\n",
    "\n",
    "# On importe les librairies dont on aura besoin pour ce tp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "## plot : \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = [15, 5]\n",
    "## stat / model : \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import itertools as IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import data : \n",
    "\n",
    "I have decided to extract the data labeled with the french nutriscore, to set a cleanning method and then decide the application I want to propose. I have in a first place look at a small subset extracted with the website interface, then I downloaded the big data they propose ($10^6$ products). \n",
    "\n",
    "**Afterwards I would like to fetch from their json API.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## \n",
    "# ## SMALL DATA SET (calories > 0)\n",
    "# ##\n",
    "\n",
    "# filename = data_path+\"openfoodfacts_with_cholesterol.csv\"\n",
    "# df = pd.read_csv(filename,\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of products in the csv : 1716277\n",
      "Number of variables :  184\n",
      "Number of product selected :  646577\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## THE BIG DATA SET :\n",
    "##\n",
    "## lien de telechargement du dataset (3.8 Go): \n",
    "## https://static.openfoodfacts.org/data/en.openfoodfacts.org.products.csv\n",
    "\n",
    "filename = data_path+\"en.openfoodfacts.org.products.csv\"\n",
    "\n",
    "# GET THE NUMBER OF LINES : \n",
    "# bash code : cat en.openfoodfacts.org.products.csv | wc -l\n",
    "# pandas (long to run) : print(pd.read_csv(filename, sep = \"\\t\", usecols = [\"code\"],dtype = \"str\", squeeze=True))\n",
    "with open(filename) as f:\n",
    "    print(\"Number of products in the csv :\", len(f.readlines())-1)\n",
    "\n",
    "## GET INDEX OF NUTRI SCORE IN COLUMNS : \n",
    "tmp = pd.read_csv(filename, sep = \"\\t\", nrows = 1).columns\n",
    "col_index = np.where(tmp==\"nutrition-score-fr_100g\")[0][0]\n",
    "col_index\n",
    "\n",
    "## OPEN FILE WITH ITERATOR CHUNKS SELECTING ROWS WITH INFO ON col_index : :\n",
    "def valid(chunks):\n",
    "    for chunk in chunks:\n",
    "        mask = ~chunk.iloc[:,col_index].isna().values\n",
    "        yield chunk.loc[mask]            \n",
    "chunksize = 10 ** 4\n",
    "chunks = pd.read_csv(filename, sep = \"\\t\", low_memory=False, chunksize=chunksize, header=None)\n",
    "df_original = pd.concat(valid(chunks))\n",
    "print(\"Number of variables : \", df_original.shape[1])\n",
    "print(\"Number of product selected : \", df_original.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk method does not allow to set header, so let's do it : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>url</th>\n",
       "      <th>creator</th>\n",
       "      <th>created_t</th>\n",
       "      <th>created_datetime</th>\n",
       "      <th>last_modified_t</th>\n",
       "      <th>last_modified_datetime</th>\n",
       "      <th>product_name</th>\n",
       "      <th>abbreviated_product_name</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>...</th>\n",
       "      <th>carbon-footprint-from-meat-or-fish_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>nutrition-score-uk_100g</th>\n",
       "      <th>glycemic-index_100g</th>\n",
       "      <th>water-hardness_100g</th>\n",
       "      <th>choline_100g</th>\n",
       "      <th>phylloquinone_100g</th>\n",
       "      <th>beta-glucan_100g</th>\n",
       "      <th>inositol_100g</th>\n",
       "      <th>carnitine_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000000100</td>\n",
       "      <td>http://world-en.openfoodfacts.org/product/0000...</td>\n",
       "      <td>del51</td>\n",
       "      <td>1444572561</td>\n",
       "      <td>2015-10-11T14:09:21Z</td>\n",
       "      <td>1444659212</td>\n",
       "      <td>2015-10-12T14:13:32Z</td>\n",
       "      <td>moutarde au moût de raisin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0000000000949</td>\n",
       "      <td>http://world-en.openfoodfacts.org/product/0000...</td>\n",
       "      <td>kiliweb</td>\n",
       "      <td>1523440813</td>\n",
       "      <td>2018-04-11T10:00:13Z</td>\n",
       "      <td>1565268412</td>\n",
       "      <td>2019-08-08T12:46:52Z</td>\n",
       "      <td>Salade de carottes râpées</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0            code                                                url  creator  \\\n",
       "4   0000000000100  http://world-en.openfoodfacts.org/product/0000...    del51   \n",
       "15  0000000000949  http://world-en.openfoodfacts.org/product/0000...  kiliweb   \n",
       "\n",
       "0    created_t      created_datetime last_modified_t last_modified_datetime  \\\n",
       "4   1444572561  2015-10-11T14:09:21Z      1444659212   2015-10-12T14:13:32Z   \n",
       "15  1523440813  2018-04-11T10:00:13Z      1565268412   2019-08-08T12:46:52Z   \n",
       "\n",
       "0                   product_name abbreviated_product_name generic_name  ...  \\\n",
       "4    moutarde au moût de raisin                       NaN          NaN  ...   \n",
       "15     Salade de carottes râpées                      NaN          NaN  ...   \n",
       "\n",
       "0  carbon-footprint-from-meat-or-fish_100g nutrition-score-fr_100g  \\\n",
       "4                                      NaN                      18   \n",
       "15                                     NaN                       1   \n",
       "\n",
       "0  nutrition-score-uk_100g glycemic-index_100g water-hardness_100g  \\\n",
       "4                      NaN                 NaN                 NaN   \n",
       "15                     NaN                 NaN                 NaN   \n",
       "\n",
       "0  choline_100g phylloquinone_100g beta-glucan_100g inositol_100g  \\\n",
       "4           NaN                NaN              NaN           NaN   \n",
       "15          NaN                NaN              NaN           NaN   \n",
       "\n",
       "0  carnitine_100g  \n",
       "4             NaN  \n",
       "15            NaN  \n",
       "\n",
       "[2 rows x 184 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_original.drop(0, axis=0)\n",
    "df.columns = df_original.loc[0,:]\n",
    "n = df.shape[0]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "df.shape[0]": "646576"
    }
   },
   "source": [
    "The data is huge ({{df.shape[0]}} products).\n",
    "Let's first work on a sample of size 10 000, and then comment this part : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 184)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(10000, replace = False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Drop columns with too many missing  values : \n",
    "Let's remove the variables with too much NaN. First, I remove the columns filled with NaNs (there is no information in them). \n",
    "\n",
    "Then, I have chosen to keep the 1st quantile value of the number of NaNs in each variables : \n",
    "* if the variable has less NaNs than this quantile, I will estimate the missing value with KNN procedure, \n",
    "* else, I drop the corresponding column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  0 variables without any information (all NaNs)\n",
      "I drop variables with more than 7241.929347826087 NaNs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>url</th>\n",
       "      <th>creator</th>\n",
       "      <th>created_t</th>\n",
       "      <th>created_datetime</th>\n",
       "      <th>last_modified_t</th>\n",
       "      <th>last_modified_datetime</th>\n",
       "      <th>product_name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>packaging</th>\n",
       "      <th>...</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>vitamin-a_100g</th>\n",
       "      <th>vitamin-c_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>9968</td>\n",
       "      <td>3788</td>\n",
       "      <td>2813</td>\n",
       "      <td>...</td>\n",
       "      <td>9981.0</td>\n",
       "      <td>5881.0</td>\n",
       "      <td>9982.0</td>\n",
       "      <td>9987.0</td>\n",
       "      <td>9987.0</td>\n",
       "      <td>2897.0</td>\n",
       "      <td>2981.0</td>\n",
       "      <td>3709.0</td>\n",
       "      <td>3663.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>628</td>\n",
       "      <td>9902</td>\n",
       "      <td>9900</td>\n",
       "      <td>9863</td>\n",
       "      <td>9862</td>\n",
       "      <td>9425</td>\n",
       "      <td>1098</td>\n",
       "      <td>1454</td>\n",
       "      <td>...</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>811481020537</td>\n",
       "      <td>http://world-en.openfoodfacts.org/product/0040...</td>\n",
       "      <td>kiliweb</td>\n",
       "      <td>1587671207</td>\n",
       "      <td>2020-04-23T19:46:47Z</td>\n",
       "      <td>1614416585</td>\n",
       "      <td>2021-02-27T09:03:05Z</td>\n",
       "      <td>Ice cream</td>\n",
       "      <td>200 g</td>\n",
       "      <td>sachet,plastique</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3674</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>175</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0               code                                                url  \\\n",
       "count          10000                                              10000   \n",
       "unique         10000                                              10000   \n",
       "top     811481020537  http://world-en.openfoodfacts.org/product/0040...   \n",
       "freq               1                                                  1   \n",
       "\n",
       "0       creator   created_t      created_datetime  last_modified_t  \\\n",
       "count     10000       10000                 10000            10000   \n",
       "unique      628        9902                  9900             9863   \n",
       "top     kiliweb  1587671207  2020-04-23T19:46:47Z       1614416585   \n",
       "freq       3674           3                     3                4   \n",
       "\n",
       "0      last_modified_datetime product_name quantity         packaging  ...  \\\n",
       "count                   10000         9968     3788              2813  ...   \n",
       "unique                   9862         9425     1098              1454  ...   \n",
       "top      2021-02-27T09:03:05Z    Ice cream    200 g  sachet,plastique  ...   \n",
       "freq                        4           15      175                68  ...   \n",
       "\n",
       "0      sugars_100g fiber_100g proteins_100g salt_100g sodium_100g  \\\n",
       "count       9981.0     5881.0        9982.0    9987.0      9987.0   \n",
       "unique      1587.0      298.0        1191.0    1516.0      1479.0   \n",
       "top            0.0        0.0           0.0       0.0         0.0   \n",
       "freq        1396.0     1808.0        1020.0    1087.0      1087.0   \n",
       "\n",
       "0      vitamin-a_100g vitamin-c_100g calcium_100g iron_100g  \\\n",
       "count          2897.0         2981.0       3709.0    3663.0   \n",
       "unique          461.0          284.0        405.0     491.0   \n",
       "top               0.0            0.0          0.0       0.0   \n",
       "freq           1520.0         1860.0       1111.0    1070.0   \n",
       "\n",
       "0      nutrition-score-fr_100g  \n",
       "count                  10000.0  \n",
       "unique                    79.0  \n",
       "top                       14.0  \n",
       "freq                     540.0  \n",
       "\n",
       "[4 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "## TACKLE MISSING VALUES 1 (drop col)\n",
    "##\n",
    "\n",
    "## DROP COL FILLED WITH NANs\n",
    "df = df.loc[:,df.isna().sum(axis=0)<n]\n",
    "print(\"There are \", sum(df.isna().sum(axis=0)==n), \"variables without any information (all NaNs)\")\n",
    "\n",
    "## DROP COL WITH MORE NANs THAN THE MEAN/1st QUANTILE :\n",
    "nan_repartition = df.isna().sum(axis=0)\n",
    "# nan_threshold = nan_repartition.quantile(0.25)\n",
    "nan_threshold = nan_repartition.mean()\n",
    "print(\"I drop variables with more than\", nan_threshold, \"NaNs\")\n",
    "df = df.drop(df.columns[nan_repartition>nan_threshold], axis = 1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploration of the columns values, set types :\n",
    "\n",
    "Then, I used the description data in https://world.openfoodfacts.org/data/data-fields.txt, to separate the global data frame into sub-frames. \n",
    "Note : to transform the .txt into these lists of variables, I used the bash command : \n",
    "\n",
    "    cat data-fields.txt | cut -d \" \" -f 1 | sed s/://g | sed s/\\$/\\\",/g | sed s/\\^/\\\"/g > data_fields2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE BASH cat data-fields.txt | cut -d \" \" -f 1 | sed s/://g | sed s/\\$/\\\",/g | sed s/\\^/\\\"/g > data_fields2.txt\n",
    "list_of_characteristics = [\"code\",\"url\",\"creator\",\"created_t\",\"created_datetime\",\"last_modified_t\",\n",
    "                           \"last_modified_datetime\",\"product_name\",\"generic_name\",\"quantity\"]\n",
    "list_of_tags = [\"packaging\", \"packaging_tags\", \"brands\", \"brands_tags\", \"categories\",\n",
    "                \"categories_tags\", \"categories_fr\",\"origins\", \"origins_tags\",\"manufacturing_places\",\n",
    "                \"manufacturing_places_tags\", \"labels\", \"labels_tags\", \"labels_fr\", \"emb_codes\", \n",
    "                \"emb_codes_tags\", \"first_packaging_code_geo\", \"cities\", \"cities_tags\", \n",
    "                \"purchase_places\", \"stores\", \"countries\", \"countries_tags\", \"countries_fr\"]\n",
    "list_of_ingredients = [\"ingredients_text\", \"traces\", \"traces_tags\"]\n",
    "list_of_misc = [\"serving_size\", \"no_nutriments\", \"additives_n\", \"additives\", \"additives_tags\", \n",
    "                \"ingredients_from_palm_oil_n\", \"ingredients_from_palm_oil\", \n",
    "                \"ingredients_from_palm_oil_tags\", \"ingredients_that_may_be_from_palm_oil_n\", \n",
    "                \"ingredients_that_may_be_from_palm_oil\", \"ingredients_that_may_be_from_palm_oil_tags\", \n",
    "                \"nutrition_grade_fr\", \"main_category\", \"main_category_fr\", \"image_url\", \n",
    "                \"image_small_url\"]\n",
    "list_of_nutri_facts = [\"energy_100g\",\"energy-kj_100g\",\"energy-kcal_100g\",\"proteins_100g\",\"casein_100g\",\n",
    "                       \"serum-proteins_100g\",\"nucleotides_100g\",\"carbohydrates_100g\",\"sugars_100g\",\n",
    "                       \"sucrose_100g\",\"glucose_100g\",\"fructose_100g\",\"lactose_100g\",\"maltose_100g\",\n",
    "                       \"maltodextrins_100g\",\"starch_100g\",\"polyols_100g\",\"fat_100g\",\"saturated-fat_100g\",\n",
    "                       \"butyric-acid_100g\",\"caproic-acid_100g\",\"caprylic-acid_100g\",\"capric-acid_100g\",\n",
    "                       \"lauric-acid_100g\",\"myristic-acid_100g\",\"palmitic-acid_100g\",\"stearic-acid_100g\",\n",
    "                       \"arachidic-acid_100g\",\"behenic-acid_100g\",\"lignoceric-acid_100g\",\"cerotic-acid_100g\",\n",
    "                       \"montanic-acid_100g\",\"melissic-acid_100g\",\"monounsaturated-fat_100g\",\n",
    "                       \"polyunsaturated-fat_100g\",\"omega-3-fat_100g\",\"alpha-linolenic-acid_100g\",\n",
    "                       \"eicosapentaenoic-acid_100g\",\"docosahexaenoic-acid_100g\",\"omega-6-fat_100g\",\n",
    "                       \"linoleic-acid_100g\",\"arachidonic-acid_100g\",\"gamma-linolenic-acid_100g\",\n",
    "                       \"dihomo-gamma-linolenic-acid_100g\",\"omega-9-fat_100g\",\"oleic-acid_100g\",\n",
    "                       \"elaidic-acid_100g\",\"gondoic-acid_100g\",\"mead-acid_100g\",\"erucic-acid_100g\",\n",
    "                       \"nervonic-acid_100g\",\"trans-fat_100g\",\"cholesterol_100g\",\"fiber_100g\",\"sodium_100g\",\n",
    "                       \"alcohol_100g\",\"vitamin-a_100g\",\"vitamin-d_100g\",\"vitamin-e_100g\",\"vitamin-k_100g\",\n",
    "                       \"vitamin-c_100g\",\"vitamin-b1_100g\",\"vitamin-b2_100g\",\"vitamin-pp_100g\",\n",
    "                       \"vitamin-b6_100g\",\"vitamin-b9_100g\",\"vitamin-b12_100g\",\"biotin_100g\",\n",
    "                       \"pantothenic-acid_100g\",\"silica_100g\",\"bicarbonate_100g\",\"potassium_100g\",\n",
    "                       \"chloride_100g\",\"calcium_100g\",\"phosphorus_100g\",\"iron_100g\",\"magnesium_100g\",\n",
    "                       \"zinc_100g\",\"copper_100g\",\"manganese_100g\",\"fluoride_100g\",\"selenium_100g\",\n",
    "                       \"chromium_100g\",\"molybdenum_100g\",\"iodine_100g\",\"caffeine_100g\",\"taurine_100g\",\n",
    "                       \"ph_100g\",\"fruits-vegetables-nuts_100g\",\"carbon-footprint_100g\",\n",
    "                       \"nutrition-score-fr_100g\",\"nutrition-score-uk_100g\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I used this partition to explore the data : these category allowed me to have an idea of the values of each variable in one hand and to determine the good type of each variable (set just after). I used the following functionm changing the category of the varibles. To ease the re-utilisation of this code, I commented the different possibilities : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- energy_100g\n",
      "ex of values =  [820.0 2092.0 1167.0 1540.0 335.0 1586.0 368.0 1071.0]\n",
      "-- energy-kj_100g  : no data\n",
      "-- energy-kcal_100g\n",
      "ex of values =  [339.0 286.0 118.0 379.0 214.0 263.0 219.0 266.0]\n",
      "-- proteins_100g\n",
      "ex of values =  [18.0 22.0 7.4 1.0 11.0 5.0 15.0 50.0]\n",
      "-- casein_100g  : no data\n",
      "-- serum-proteins_100g  : no data\n",
      "-- nucleotides_100g  : no data\n",
      "-- carbohydrates_100g\n",
      "ex of values =  [40.799999237061 0.0 10.67 53.0 1.0 13.27 0.0 0.83]\n",
      "-- sugars_100g\n",
      "ex of values =  [11.18 2.4 3.0 25.0 1.79 0.0 34.2 25.81]\n",
      "-- sucrose_100g  : no data\n",
      "-- glucose_100g  : no data\n",
      "-- fructose_100g  : no data\n",
      "-- lactose_100g  : no data\n",
      "-- maltose_100g  : no data\n",
      "-- maltodextrins_100g  : no data\n",
      "-- starch_100g  : no data\n",
      "-- polyols_100g  : no data\n",
      "-- fat_100g\n",
      "ex of values =  [61.6 15.0 18.0 0.5 28.0 53.33 16.2 39.0]\n",
      "-- saturated-fat_100g\n",
      "ex of values =  [0.0 1.0 4.55 10.71 0.0 0.0 22.6 10.5]\n",
      "-- butyric-acid_100g  : no data\n",
      "-- caproic-acid_100g  : no data\n",
      "-- caprylic-acid_100g  : no data\n",
      "-- capric-acid_100g  : no data\n",
      "-- lauric-acid_100g  : no data\n",
      "-- myristic-acid_100g  : no data\n",
      "-- palmitic-acid_100g  : no data\n",
      "-- stearic-acid_100g  : no data\n",
      "-- arachidic-acid_100g  : no data\n",
      "-- behenic-acid_100g  : no data\n",
      "-- lignoceric-acid_100g  : no data\n",
      "-- cerotic-acid_100g  : no data\n",
      "-- montanic-acid_100g  : no data\n",
      "-- melissic-acid_100g  : no data\n",
      "-- monounsaturated-fat_100g  : no data\n",
      "-- polyunsaturated-fat_100g  : no data\n",
      "-- omega-3-fat_100g  : no data\n",
      "-- alpha-linolenic-acid_100g  : no data\n",
      "-- eicosapentaenoic-acid_100g  : no data\n",
      "-- docosahexaenoic-acid_100g  : no data\n",
      "-- omega-6-fat_100g  : no data\n",
      "-- linoleic-acid_100g  : no data\n",
      "-- arachidonic-acid_100g  : no data\n",
      "-- gamma-linolenic-acid_100g  : no data\n",
      "-- dihomo-gamma-linolenic-acid_100g  : no data\n",
      "-- omega-9-fat_100g  : no data\n",
      "-- oleic-acid_100g  : no data\n",
      "-- elaidic-acid_100g  : no data\n",
      "-- gondoic-acid_100g  : no data\n",
      "-- mead-acid_100g  : no data\n",
      "-- erucic-acid_100g  : no data\n",
      "-- nervonic-acid_100g  : no data\n",
      "-- trans-fat_100g\n",
      "ex of values =  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      "-- cholesterol_100g\n",
      "ex of values =  [0.0 0.02 0.056 0.008 0.0 0.047 0.0 '0.013']\n",
      "-- fiber_100g\n",
      "ex of values =  [0.0 0.0 1.1 0.0 2.0 7.9 1.1 2.4]\n",
      "-- sodium_100g\n",
      "ex of values =  [0.04 0.208 0.392 0.562 0.00508 1.389 0.04 0.004]\n",
      "-- alcohol_100g  : no data\n",
      "-- vitamin-a_100g\n",
      "ex of values =  [0.0002121 0.000183 5.16e-05 0.0 2.1e-05 0.0 7.14e-05 0.0]\n",
      "-- vitamin-d_100g  : no data\n",
      "-- vitamin-e_100g  : no data\n",
      "-- vitamin-k_100g  : no data\n",
      "-- vitamin-c_100g\n",
      "ex of values =  [0.0 0.0 0.004 0.0 0.002 0.0 0.0 0.0]\n",
      "-- vitamin-b1_100g  : no data\n",
      "-- vitamin-b2_100g  : no data\n",
      "-- vitamin-pp_100g  : no data\n",
      "-- vitamin-b6_100g  : no data\n",
      "-- vitamin-b9_100g  : no data\n",
      "-- vitamin-b12_100g  : no data\n",
      "-- biotin_100g  : no data\n",
      "-- pantothenic-acid_100g  : no data\n",
      "-- silica_100g  : no data\n",
      "-- bicarbonate_100g  : no data\n",
      "-- potassium_100g  : no data\n",
      "-- chloride_100g  : no data\n",
      "-- calcium_100g\n",
      "ex of values =  [0.0 0.0 0.0 0.0 0.0 0.02 0.0 0.082]\n",
      "-- phosphorus_100g  : no data\n",
      "-- iron_100g\n",
      "ex of values =  [0.00138 0.00321 8e-05 0.0 0.0 0.0 0.0 0.0036]\n",
      "-- magnesium_100g  : no data\n",
      "-- zinc_100g  : no data\n",
      "-- copper_100g  : no data\n",
      "-- manganese_100g  : no data\n",
      "-- fluoride_100g  : no data\n",
      "-- selenium_100g  : no data\n",
      "-- chromium_100g  : no data\n",
      "-- molybdenum_100g  : no data\n",
      "-- iodine_100g  : no data\n",
      "-- caffeine_100g  : no data\n",
      "-- taurine_100g  : no data\n",
      "-- ph_100g  : no data\n",
      "-- fruits-vegetables-nuts_100g  : no data\n",
      "-- carbon-footprint_100g  : no data\n",
      "-- nutrition-score-fr_100g\n",
      "ex of values =  [19.0 23.0 -4.0 9.0 14.0 3.0 25.0 0.0]\n",
      "-- nutrition-score-uk_100g  : no data\n"
     ]
    }
   ],
   "source": [
    "def print_values_from_list_of_var(df_,list_of_var):\n",
    "    for var in list_of_var : \n",
    "        if var in df_.columns:\n",
    "            print(\"--\",var)\n",
    "            tmp = df_[df_.columns.intersection([var])]\n",
    "            var_values = tmp.iloc[(~pd.isna(tmp).values)]\n",
    "            if len(var_values) < 8:\n",
    "                print(\"values = \", var_values.values)\n",
    "            else :\n",
    "                print(\"ex of values = \", \n",
    "                      np.array(tmp.iloc[(~pd.isna(tmp).values)].sample(n=8).values).transpose()[0])\n",
    "        else : \n",
    "            print(\"--\", var, \" : no data\")\n",
    "            \n",
    "# list_of_var = list_of_characteristics\n",
    "# list_of_var = list_of_tags\n",
    "# list_of_var = list_of_ingredients\n",
    "# list_of_var = list_of_misc\n",
    "list_of_var = list_of_nutri_facts\n",
    "print_values_from_list_of_var(df,list_of_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variable-type analysis allowed me to select the non-relevant variables for my study, such as the dates. I have keep some variables like the country or the name of the person that put the product in the database, just for the exercice to clean text data. This subset will be call \"data\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_var = pd.Index([\"code\",\"product_name\",\"creator\",\"countries\",\"additives_n\",\"ingredients_from_palm_oil_n\",\n",
    "                \"ingredients_that_may_be_from_palm_oil_tags\"])\n",
    "interest_var = interest_var.append(df.columns.intersection(list_of_nutri_facts))\n",
    "\n",
    "data = df[df.columns.intersection(interest_var)].copy()\n",
    "# data = data.fillna(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GESTION DES TYPES DANS DATA !!\n",
    "## STR \n",
    "str_var = list_of_characteristics \n",
    "str_var += list_of_tags\n",
    "str_var += list_of_ingredients\n",
    "str_var += list_of_misc\n",
    "str_var = data.columns.intersection(str_var).values\n",
    "data[str_var] = data[str_var].astype(\"str\")\n",
    "\n",
    "## FLOATS (and INTs)\n",
    "float_var = list_of_nutri_facts\n",
    "float_var += [\"additives_n\", \"ingredients_from_palm_oil_n\",\"ingredients_from_palm_oil_n\",\n",
    "              \"ingredients_that_may_be_from_palm_oil_tags\"]\n",
    "float_var = data.columns.intersection(float_var).values\n",
    "data[float_var] = data[float_var].astype(\"float\")\n",
    "\n",
    "## CATEGORY\n",
    "data[\"creator\"] = data[[\"creator\",\"nutrition-score-fr_100g\"]].astype(\"category\")\n",
    "# data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the float types are ok, I can call the \"describe\" method of pandas, to see the summary of the descriptive statistics : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additives_n</th>\n",
       "      <th>ingredients_from_palm_oil_n</th>\n",
       "      <th>energy-kcal_100g</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>trans-fat_100g</th>\n",
       "      <th>cholesterol_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>vitamin-a_100g</th>\n",
       "      <th>vitamin-c_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7323.000000</td>\n",
       "      <td>7323.000000</td>\n",
       "      <td>9365.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>9982.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>3629.000000</td>\n",
       "      <td>3685.000000</td>\n",
       "      <td>9977.000000</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>5881.000000</td>\n",
       "      <td>9982.000000</td>\n",
       "      <td>9987.000000</td>\n",
       "      <td>2897.000000</td>\n",
       "      <td>2981.000000</td>\n",
       "      <td>3709.000000</td>\n",
       "      <td>3663.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.162365</td>\n",
       "      <td>0.020893</td>\n",
       "      <td>284.741305</td>\n",
       "      <td>1177.156277</td>\n",
       "      <td>14.609416</td>\n",
       "      <td>5.327353</td>\n",
       "      <td>0.044689</td>\n",
       "      <td>0.036904</td>\n",
       "      <td>28.559480</td>\n",
       "      <td>13.096413</td>\n",
       "      <td>2.846513</td>\n",
       "      <td>8.549485</td>\n",
       "      <td>0.538138</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>0.099380</td>\n",
       "      <td>0.006553</td>\n",
       "      <td>9.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.007319</td>\n",
       "      <td>0.143988</td>\n",
       "      <td>193.359379</td>\n",
       "      <td>803.132101</td>\n",
       "      <td>17.934440</td>\n",
       "      <td>7.839156</td>\n",
       "      <td>0.900154</td>\n",
       "      <td>0.942379</td>\n",
       "      <td>27.484599</td>\n",
       "      <td>18.571170</td>\n",
       "      <td>4.604325</td>\n",
       "      <td>8.929822</td>\n",
       "      <td>5.284767</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.527017</td>\n",
       "      <td>0.265047</td>\n",
       "      <td>0.149076</td>\n",
       "      <td>8.962446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>471.000000</td>\n",
       "      <td>1.202500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>1118.000000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.670000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>0.252000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>412.000000</td>\n",
       "      <td>1703.000000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>53.570000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>12.120000</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1944.000000</td>\n",
       "      <td>8134.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>56.300000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0      additives_n  ingredients_from_palm_oil_n  energy-kcal_100g  \\\n",
       "count  7323.000000                  7323.000000       9365.000000   \n",
       "mean      2.162365                     0.020893        284.741305   \n",
       "std       3.007319                     0.143988        193.359379   \n",
       "min       0.000000                     0.000000          0.000000   \n",
       "25%       0.000000                     0.000000        116.000000   \n",
       "50%       1.000000                     0.000000        272.000000   \n",
       "75%       3.000000                     0.000000        412.000000   \n",
       "max      27.000000                     2.000000       1944.000000   \n",
       "\n",
       "0      energy_100g     fat_100g  saturated-fat_100g  trans-fat_100g  \\\n",
       "count  9981.000000  9982.000000         9981.000000     3629.000000   \n",
       "mean   1177.156277    14.609416            5.327353        0.044689   \n",
       "std     803.132101    17.934440            7.839156        0.900154   \n",
       "min       0.000000     0.000000            0.000000        0.000000   \n",
       "25%     471.000000     1.202500            0.100000        0.000000   \n",
       "50%    1118.000000     8.330000            2.070000        0.000000   \n",
       "75%    1703.000000    22.900000            7.800000        0.000000   \n",
       "max    8134.000000   100.000000          100.000000       50.000000   \n",
       "\n",
       "0      cholesterol_100g  carbohydrates_100g  sugars_100g   fiber_100g  \\\n",
       "count       3685.000000         9977.000000  9981.000000  5881.000000   \n",
       "mean           0.036904           28.559480    13.096413     2.846513   \n",
       "std            0.942379           27.484599    18.571170     4.604325   \n",
       "min            0.000000            0.000000     0.000000     0.000000   \n",
       "25%            0.000000            4.170000     0.800000     0.000000   \n",
       "50%            0.000000           16.670000     3.800000     1.600000   \n",
       "75%            0.024000           53.570000    19.000000     3.600000   \n",
       "max           56.300000          151.000000   148.000000    85.500000   \n",
       "\n",
       "0      proteins_100g  sodium_100g  vitamin-a_100g  vitamin-c_100g  \\\n",
       "count    9982.000000  9987.000000     2897.000000     2981.000000   \n",
       "mean        8.549485     0.538138        0.000125        0.021930   \n",
       "std         8.929822     5.284767        0.000408        0.527017   \n",
       "min         0.000000     0.000000        0.000000        0.000000   \n",
       "25%         2.000000     0.040000        0.000000        0.000000   \n",
       "50%         6.100000     0.252000        0.000000        0.000000   \n",
       "75%        12.120000     0.548000        0.000107        0.003300   \n",
       "max       100.000000   345.000000        0.008500       24.000000   \n",
       "\n",
       "0      calcium_100g    iron_100g  nutrition-score-fr_100g  \n",
       "count   3709.000000  3663.000000             10000.000000  \n",
       "mean       0.099380     0.006553                 9.301000  \n",
       "std        0.265047     0.149076                 8.962446  \n",
       "min        0.000000     0.000000               -14.000000  \n",
       "25%        0.000000     0.000000                 2.000000  \n",
       "50%        0.038000     0.000970                10.000000  \n",
       "75%        0.111000     0.002400                16.000000  \n",
       "max       12.000000     7.000000                34.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Special column treatment \n",
    "## 4. 1. Modification of \"ingredients_drom_palm_oil_n\" \n",
    "\n",
    "This variable was not well documented, my idea is to go back to a simple boolean variable : is there (or not) some ingredients with palm oil ? The issue is that there already exists such a variable. If it is not in my dataset, I create a new variable, if it is, I concat the 2 variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## dev code ###################\n",
    "##\n",
    "## 1st idea of code : \n",
    "##\n",
    "\n",
    "data2 = data.copy()\n",
    "if \"ingredients_from_palm_oil_n\" in data2.columns :\n",
    "    if ~(\"ingredients_from_palm_oil\" in data2.columns) :\n",
    "        data2.insert(loc = data2.columns.get_loc(\"ingredients_from_palm_oil_n\"),\n",
    "                    column = \"ingredients_from_palm_oil\",\n",
    "                    value = 0)\n",
    "        index_1 = data2[data2[\"ingredients_from_palm_oil_n\"]==1].index\n",
    "        data2.at[index_1,\"ingredients_from_palm_oil\"] = 1\n",
    "        index_nan = data2[pd.isna(data2[\"ingredients_from_palm_oil_n\"])].index\n",
    "        data2.at[index_nan,\"ingredients_from_palm_oil\"] = np.nan\n",
    "        \n",
    "    data2.drop(\"ingredients_from_palm_oil_n\", axis=1, inplace = True)\n",
    "data2.iloc[:,3:10]\n",
    "\n",
    "## \n",
    "## after reflexion, better to do modify directly the line :\n",
    "##\n",
    "\n",
    "data2 = data.copy()\n",
    "if \"ingredients_from_palm_oil_n\" in data2.columns :\n",
    "    if ~(\"ingredients_from_palm_oil\" in data2.columns) :\n",
    "        data2.at[data2[\"ingredients_from_palm_oil_n\"] > 0, \"ingredients_from_palm_oil_n\"] = 1\n",
    "        data2.rename(columns={\"ingredients_from_palm_oil_n\":\"ingredients_from_palm_oil\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to modify some of my variables : \n",
    "* if there is no \"ingredients_from_palm_oil\" but a \"ingredients_from_palm_oil_n\" colunm, I transformed this one into the first one.\n",
    "* if there is a \"ingredients_from_palm_oil\" column and a \"ingredients_from_palm_oil_n\" column, I used the same boolenization and fill the missing values of the first with this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start to isolate the code I want to re-use to define my prepocess method **(idea : object oriented programmation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    if \"ingredients_from_palm_oil_n\" in data.columns :\n",
    "        data.at[data[\"ingredients_from_palm_oil_n\"] > 0, \"ingredients_from_palm_oil_n\"] = 1\n",
    "        if (\"ingredients_from_palm_oil\" in data.columns) :\n",
    "            data['ingredients_from_palm_oil'].fillna(data['ingredients_from_palm_oil_n'], inplace=True)\n",
    "            data.drop(\"ingredients_from_palm_oil_n\", inplace = True, axis = 1)\n",
    "        else :\n",
    "            data.rename(columns={\"ingredients_from_palm_oil_n\":\"ingredients_from_palm_oil\"}, inplace=True)\n",
    "## to test, creation of a fictive column :             \n",
    "# data2 = data.copy()\n",
    "# data2.at[:,\"ingredients_from_palm_oil\"] = np.where(data2[\"nutrition-score-fr_100g\"]<0,0,np.nan)\n",
    "# data2.at[data2[\"nutrition-score-fr_100g\"]>20,\"ingredients_from_palm_oil\"] = 1\n",
    "\n",
    "preprocess_data(data)\n",
    "float_var[float_var==\"ingredients_from_palm_oil_n\"] = \"ingredients_from_palm_oil\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Errors in numerical data - outliers :\n",
    "\n",
    "I had so many variables to check ! \n",
    "To ease this work, I propose the following procedure :\n",
    "\n",
    "* 1. graphical reading : to plot the histograms allowed me to pre-select the possible values for each variables. For example, much of the data \"_100g\" have values above 100, that can not be normal. \n",
    "* 2. Put the possible values in a dictonary and ajust it for every variables, to select the outliers or error data. \n",
    "* 3. Have a breaf check to be sure that the data I dropped was in deed outliers.\n",
    "\n",
    "\n",
    "<!-- In the course, they decompose data in 5 classes : \n",
    "* lexical errors\n",
    "* irregularity error\n",
    "* Formatage error\n",
    "* Duplicates\n",
    "* Outliers -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1440 with 18 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_line_plot = int(np.floor(len(float_var)/4)+1)\n",
    "fig = plt.figure(figsize=(15, 20))\n",
    "\n",
    "fig_count = 1\n",
    "for var in float_var :#data.columns.intersection(list_of_nutri_facts):\n",
    "    ax = fig.add_subplot(nb_line_plot,4, fig_count)\n",
    "    nb_bins = min(20, len(np.unique(data[var].dropna().values)))\n",
    "    ax.hist(data[var], bins = nb_bins, color='steelblue', density=True, edgecolor='none')\n",
    "    ax.set_title(var)\n",
    "    fig_count += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ease this manual part, I used the following function, that takes the column name, the possible values we want to set, and returns the values that are not in this set of values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_irreg_errors_val(colname,possible_values, data = data):\n",
    "    outliers_val = []\n",
    "    col_values = data[colname].drop_duplicates().values\n",
    "    ## check possible values : \n",
    "    min_value, max_value = possible_values\n",
    "    for val in col_values :\n",
    "        if ~np.isnan(val) :\n",
    "            if (val < min_value) or (val > max_value):\n",
    "                outliers_val.append(val)\n",
    "        else : \n",
    "            print(sum(data[colname].isna()),\"missing values\")\n",
    "    print(len(outliers_val), \"item values out of the intervall\", possible_values)\n",
    "    return outliers_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made a dictionnary of the possible values each variable can take : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_val_dict = {'additives_n' : [0,35],'ingredients_from_palm_oil': [0,1],\n",
    "                     'energy-kcal_100g':[0,1500], 'energy_100g':[0,5000],'fat_100g':[0,100],\n",
    "                     'saturated-fat_100g': [0,100],'trans-fat_100g':[0,90], 'cholesterol_100g':[0,10],\n",
    "                     'carbohydrates_100g': [0,100], 'sugars_100g': [0,100], 'fiber_100g': [0,100],\n",
    "                     'proteins_100g': [0,100],'sodium_100g': [0,100], 'vitamin-a_100g': [0,100],\n",
    "                     'vitamin-c_100g': [0,1], 'calcium_100g': [0,20],'iron_100g': [0,0.05], \n",
    "                     'nutrition-score-fr_100g': [-20,50]}\n",
    "\n",
    "limit_val_dict = {'additives_n' : [0,25],'ingredients_from_palm_oil': [0,1],\n",
    "                  'energy-kcal_100g':[0,1000], 'energy_100g':[0,4000],'fat_100g':[0,90],\n",
    "                  'saturated-fat_100g': [0,40],'trans-fat_100g':[0,2.5], 'cholesterol_100g':[0,0.2],\n",
    "                  'carbohydrates_100g': [0,95], 'sugars_100g': [0,95], 'fiber_100g': [0,90],\n",
    "                  'proteins_100g': [0,80],'sodium_100g': [0,10], 'vitamin-a_100g': [0,0.01],\n",
    "                  'vitamin-c_100g': [0,0.3], 'calcium_100g': [0,10],'iron_100g': [0,0.04], \n",
    "                  'nutrition-score-fr_100g': [-15,35]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For clarity purposes, I just keep an example of how I proceeded to choose my possible values for each variable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635 missing values\n",
      "4 item values out of the intervall [0, 1500]\n",
      "outliers products : ['Krokante muesli vier noten' 'Krokante muesli'\n",
      " 'Véritables Rillettes du Mans sans conservateurs' 'Arlequin'] \n",
      "\n",
      "639 missing values\n",
      "7 item values out of the intervall [0, 1000]\n",
      " limit products : ['Pâté de Lapin aux Noisettes' 'Biscuits Chocotom Chocolat Tom (190G)'\n",
      " 'Saint felicien' 'Chorizo' 'Tapenade' 'quiche lorraine'\n",
      " 'Special mie nature']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2 = data.copy()\n",
    "colname = \"energy-kcal_100g\"\n",
    "possible_vals = possible_val_dict[colname]\n",
    "limit_vals = limit_val_dict[colname]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "## Histogramme global \n",
    "ax = fig.add_subplot(1,3,1)\n",
    "nb_bins = min(50, len(np.unique(data2[colname].dropna().values)))\n",
    "ax.hist(data2[colname], bins = nb_bins, color='steelblue', density=True, edgecolor='none')\n",
    "ax.set_title(\"before removing outliers \" + colname)\n",
    "\n",
    "outliers = extract_irreg_errors_val(colname,possible_vals, data = data)\n",
    "print(\"outliers products :\",np.array(data.loc[data[colname].isin(outliers), \"product_name\"]), \"\\n\")\n",
    "# replace outliers by np.nan : \n",
    "data2.at[data2[colname].isin(outliers)] = np.nan\n",
    "\n",
    "## Histogramme : \n",
    "ax = fig.add_subplot(1,3,2)\n",
    "nb_bins = min(50, len(np.unique(data2[colname].dropna().values)))\n",
    "ax.hist(data2[colname], bins = nb_bins, color='steelblue', density=True, edgecolor='none')\n",
    "ax.set_title(\"after removing outliers \" + colname)\n",
    "\n",
    "# plot values : \n",
    "ax = fig.add_subplot(1,3,3)\n",
    "ax.plot(np.sort(data2[colname]))\n",
    "\n",
    "## Print problematic variables : \n",
    "limit_products = extract_irreg_errors_val(colname, limit_vals, data = data2)\n",
    "print(\" limit products :\",\n",
    "      np.array(data.loc[data[colname].isin(limit_products), \"product_name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible values set, let's drop the corresponding values in our dataset. \n",
    "\n",
    "Note that if one product has more that half of the columns with outliers, we may want to drop it, so I construct an outlier counter, and add it with the number of missing values already present.\n",
    "**To be added to preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2_data(possible_val_dict,data):\n",
    "    count_outliers = pd.Series(data.isna().sum(axis = 1),index = data.index)\n",
    "    for colname in data.columns.intersection(possible_val_dict.keys()) : \n",
    "        outliers_index = data[colname].isin(limit_products)\n",
    "        count_outliers[outliers_index]+=1\n",
    "        data.loc[outliers_index,colname] = np.nan\n",
    "    ## drop products where to more than half missing values : \n",
    "    to_drop_products = count_outliers[count_outliers>(int(len(data.columns)/2)+1)].index\n",
    "    data.drop(to_drop_products, axis = 0, inplace = True)\n",
    "preprocess2_data(possible_val_dict,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>creator</th>\n",
       "      <th>countries</th>\n",
       "      <th>additives_n</th>\n",
       "      <th>ingredients_from_palm_oil</th>\n",
       "      <th>energy-kcal_100g</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>trans-fat_100g</th>\n",
       "      <th>...</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>vitamin-a_100g</th>\n",
       "      <th>vitamin-c_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1581021</th>\n",
       "      <td>8436021257697</td>\n",
       "      <td>elcoco</td>\n",
       "      <td>España</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>229.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>9.80</td>\n",
       "      <td>3.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25.80</td>\n",
       "      <td>2.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>0011110877796</td>\n",
       "      <td>usda-ndb-import</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>32.14</td>\n",
       "      <td>17.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254525</th>\n",
       "      <td>93133274769</td>\n",
       "      <td>usda-ndb-import</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.53</td>\n",
       "      <td>17.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32228</th>\n",
       "      <td>0018894463009</td>\n",
       "      <td>usda-ndb-import</td>\n",
       "      <td>United States</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.88</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.77</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.00298</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10223</th>\n",
       "      <td>0011110970442</td>\n",
       "      <td>usda-ndb-import</td>\n",
       "      <td>United States</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>23.08</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.46</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00166</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                 code          creator      countries  additives_n  \\\n",
       "1581021  8436021257697           elcoco         España          NaN   \n",
       "9373     0011110877796  usda-ndb-import  United States          1.0   \n",
       "254525     93133274769  usda-ndb-import  United States          1.0   \n",
       "32228    0018894463009  usda-ndb-import  United States          3.0   \n",
       "10223    0011110970442  usda-ndb-import  United States          3.0   \n",
       "\n",
       "0        ingredients_from_palm_oil  energy-kcal_100g  energy_100g  fat_100g  \\\n",
       "1581021                        NaN             229.0        958.0      9.80   \n",
       "9373                           0.0             393.0       1644.0     32.14   \n",
       "254525                         0.0              88.0        368.0      0.00   \n",
       "32228                          0.0             246.0       1029.0      1.75   \n",
       "10223                          0.0             308.0       1289.0     23.08   \n",
       "\n",
       "0        saturated-fat_100g  trans-fat_100g  ...  carbohydrates_100g  \\\n",
       "1581021                3.90             NaN  ...               25.80   \n",
       "9373                  17.86             0.0  ...                3.57   \n",
       "254525                 0.00             0.0  ...               23.53   \n",
       "32228                  0.00             0.0  ...               50.88   \n",
       "10223                  7.69             0.0  ...                6.15   \n",
       "\n",
       "0        sugars_100g  fiber_100g  proteins_100g  sodium_100g  vitamin-a_100g  \\\n",
       "1581021         2.70         NaN           8.60        0.600             NaN   \n",
       "9373            0.00         0.0          25.00        0.643        0.000321   \n",
       "254525         17.65         0.0           0.00        0.529        0.000000   \n",
       "32228           1.75         1.8           8.77        0.456        0.000000   \n",
       "10223           4.62         0.0          18.46        1.031        0.000000   \n",
       "\n",
       "0        vitamin-c_100g  calcium_100g  iron_100g  nutrition-score-fr_100g  \n",
       "1581021             NaN           NaN        NaN                     11.0  \n",
       "9373             0.0000         0.714    0.00000                     16.0  \n",
       "254525           0.0071         0.000    0.00000                      9.0  \n",
       "32228            0.0000         0.053    0.00298                      2.0  \n",
       "10223            0.0018         0.000    0.00166                     21.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Estimate remaining missing values\n",
    "\n",
    "Now that we have a cleanner dataset, it is time to infer the missing values. I propose two approaches. The first one is to use automatic method implemented in the pandas library (pd.fillna, pd.interpolate). Then, as suggested in the project instructions, I infer the missing values with a KNN procedure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Pandas methods to deal with missing values\n",
    "\n",
    "Let's first see the more naive approaches, that is filling the data with the mean :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILL WITH GLOBAL MEAN VALUE : \n",
    "data_filled_with_mean = data.fillna(data2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the columns are not scaled, fill the missing values with mean seems not right : we'd better fill with the  column mean :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>creator</th>\n",
       "      <th>product_name</th>\n",
       "      <th>countries</th>\n",
       "      <th>additives_n</th>\n",
       "      <th>ingredients_from_palm_oil</th>\n",
       "      <th>energy-kcal_100g</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>...</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>vitamin-a_100g</th>\n",
       "      <th>vitamin-c_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1581021</th>\n",
       "      <td>8436021257697</td>\n",
       "      <td>elcoco</td>\n",
       "      <td>Pizza boloñesa</td>\n",
       "      <td>España</td>\n",
       "      <td>2.162365</td>\n",
       "      <td>0.020757</td>\n",
       "      <td>229.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>9.80</td>\n",
       "      <td>3.90</td>\n",
       "      <td>...</td>\n",
       "      <td>25.80</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.846513</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.02193</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.006553</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>0011110877796</td>\n",
       "      <td>usda-ndb-import</td>\n",
       "      <td>Simple truth organic, white cheddar cheese</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>393.0</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>32.14</td>\n",
       "      <td>17.86</td>\n",
       "      <td>...</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.71400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254525</th>\n",
       "      <td>93133274769</td>\n",
       "      <td>usda-ndb-import</td>\n",
       "      <td>Hawaiian Brisket Cooking Sauce</td>\n",
       "      <td>United States</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>23.53</td>\n",
       "      <td>17.65</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00710</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32228</th>\n",
       "      <td>0018894463009</td>\n",
       "      <td>usda-ndb-import</td>\n",
       "      <td>Plain English Muffins</td>\n",
       "      <td>United States</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>50.88</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>8.77</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10223</th>\n",
       "      <td>0011110970442</td>\n",
       "      <td>usda-ndb-import</td>\n",
       "      <td>Kroger, pork sausage patties, maple</td>\n",
       "      <td>United States</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>308.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>23.08</td>\n",
       "      <td>7.69</td>\n",
       "      <td>...</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.62</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.46</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00180</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                 code          creator  \\\n",
       "1581021  8436021257697           elcoco   \n",
       "9373     0011110877796  usda-ndb-import   \n",
       "254525     93133274769  usda-ndb-import   \n",
       "32228    0018894463009  usda-ndb-import   \n",
       "10223    0011110970442  usda-ndb-import   \n",
       "\n",
       "0                                      product_name      countries  \\\n",
       "1581021                              Pizza boloñesa         España   \n",
       "9373     Simple truth organic, white cheddar cheese  United States   \n",
       "254525               Hawaiian Brisket Cooking Sauce  United States   \n",
       "32228                         Plain English Muffins  United States   \n",
       "10223           Kroger, pork sausage patties, maple  United States   \n",
       "\n",
       "0        additives_n  ingredients_from_palm_oil  energy-kcal_100g  \\\n",
       "1581021     2.162365                   0.020757             229.0   \n",
       "9373        1.000000                   0.000000             393.0   \n",
       "254525      1.000000                   0.000000              88.0   \n",
       "32228       3.000000                   0.000000             246.0   \n",
       "10223       3.000000                   0.000000             308.0   \n",
       "\n",
       "0        energy_100g  fat_100g  saturated-fat_100g  ...  carbohydrates_100g  \\\n",
       "1581021        958.0      9.80                3.90  ...               25.80   \n",
       "9373          1644.0     32.14               17.86  ...                3.57   \n",
       "254525         368.0      0.00                0.00  ...               23.53   \n",
       "32228         1029.0      1.75                0.00  ...               50.88   \n",
       "10223         1289.0     23.08                7.69  ...                6.15   \n",
       "\n",
       "0        sugars_100g  fiber_100g  proteins_100g  sodium_100g  vitamin-a_100g  \\\n",
       "1581021         2.70    2.846513           8.60        0.600        0.000125   \n",
       "9373            0.00    0.000000          25.00        0.643        0.000321   \n",
       "254525         17.65    0.000000           0.00        0.529        0.000000   \n",
       "32228           1.75    1.800000           8.77        0.456        0.000000   \n",
       "10223           4.62    0.000000          18.46        1.031        0.000000   \n",
       "\n",
       "0        vitamin-c_100g  calcium_100g  iron_100g  nutrition-score-fr_100g  \n",
       "1581021         0.02193       0.09938   0.006553                     11.0  \n",
       "9373            0.00000       0.71400   0.000000                     16.0  \n",
       "254525          0.00710       0.00000   0.000000                      9.0  \n",
       "32228           0.00000       0.05300   0.002980                      2.0  \n",
       "10223           0.00180       0.00000   0.001660                     21.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filled_with_mean = data.copy()\n",
    "for colname in data.columns : \n",
    "    if pd.api.types.is_float_dtype(data[colname].dtype) : # == \"float64\":\n",
    "        data_filled_with_mean[colname].fillna(data[colname].mean(), inplace = True)\n",
    "data_filled_with_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this first approach seems to be efficient. There are some cons to use this :\n",
    "* it does not tackle the str values\n",
    "* it can introduce a bias, as the columns with many missing values will be drowned to their mean. \n",
    "\n",
    "**It can be relevant to use this method with a clustering computed before : fill the missing data cluster by cluster mean for this column.** \n",
    "\n",
    "Let's now impute the missing data with interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLOBAL INTERPOLATION : \n",
    "data_filled_interpol = data.interpolate(limit_direction='both')\n",
    "# data_filled_interpol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, even if it is easier to do that, there are issue to make a global interpolation, as the columns are not \"sorted\". A clustering approach to \"sort\" the data may improve this. \n",
    "Furthermore, the first and last lines are not imputed if the attribute \n",
    "`limit_direction='both'` is not set : **we can also think about a shuffle method**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. KNN inference : \n",
    "\n",
    "The main issues in the method that I propose before is a question of order : I is arbitrary ordered and the imputation depends strongly on that order. To get rid of this, I use a KNN. That is the missing data are computed comparing the product with the k products that the most similar in the dataset sample.\n",
    "\n",
    "### 6.2.1 sklearn.impute.KNNImputer \n",
    "\n",
    "In the sklearn library, a function does exactly what I want to do. I used the [linked tutorial](https://machinelearningmastery.com/knn-imputation-for-missing-values-in-machine-learning/) as a support for this part : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Missing values : 49673\n",
      "Remaining Missing values : 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from numpy import isnan\n",
    "\n",
    "print('Total Missing values : %d' % sum(isnan(X).flatten()))\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer.fit(X)\n",
    "Xtrans = imputer.transform(X)\n",
    "print('Remaining Missing values : %d' % sum(isnan(Xtrans).flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the tutorial, they compare this method with a random forest classifer, and use an accuracy score to compare the results. I wanted to do \"simpler\" thing and just do a cross validation. The issue is the missing values in X (that is what I and trying to solve)! They prevent me to use the \"r2\" score, or any score in sklearn.metrics because of these missing values. I see two ways to work around this : \n",
    "\n",
    "* fill missing values with column mean values in X, and infer better y\n",
    "* compute a score function that ignore the missing values\n",
    "\n",
    "<!-- As I don't have the time to do both, I choose the  idea (which seems more simpler) :  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.columns.intersection(float_var)]\n",
    "y = None\n",
    "\n",
    "# X_train, X_test = model_selection.train_test_split(X, train_size=0.8)\n",
    "X_test = X.dropna(axis = 0)\n",
    "X_train = X[ ~X.index.isin(X_test.index)]\n",
    "\n",
    "imputer = KNNImputer(weights='uniform', metric='nan_euclidean')\n",
    "param_grid = {\"n_neighbors\" : np.arange(1,10,1)}\n",
    "\n",
    "# CV_KNNImpute = model_selection.GridSearchCV(imputer, param_grid, scoring='r2', cv=5)\n",
    "# CV_KNNImpute.fit(X_train_std, y_train)\n",
    "\n",
    "pred = KNNImputer(n_neighbors=2).fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additives_n</th>\n",
       "      <th>ingredients_from_palm_oil</th>\n",
       "      <th>energy-kcal_100g</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>trans-fat_100g</th>\n",
       "      <th>cholesterol_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>vitamin-a_100g</th>\n",
       "      <th>vitamin-c_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>32.14</td>\n",
       "      <td>17.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254525</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.53</td>\n",
       "      <td>17.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32228</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>50.88</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.8</td>\n",
       "      <td>8.77</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.00298</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10223</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>23.08</td>\n",
       "      <td>7.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.46</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00166</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49283</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1674.0</td>\n",
       "      <td>8.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.00900</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>42.86</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>32.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.43</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.00257</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>25.88</td>\n",
       "      <td>9.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082</td>\n",
       "      <td>3.53</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.18</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.00085</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371169</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>24.44</td>\n",
       "      <td>15.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>77.78</td>\n",
       "      <td>31.11</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00160</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177986</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>11.43</td>\n",
       "      <td>8.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>25.71</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.29</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.00129</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2731 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0       additives_n  ingredients_from_palm_oil  energy-kcal_100g  energy_100g  \\\n",
       "9373            1.0                        0.0             393.0       1644.0   \n",
       "254525          1.0                        0.0              88.0        368.0   \n",
       "32228           3.0                        0.0             246.0       1029.0   \n",
       "10223           3.0                        0.0             308.0       1289.0   \n",
       "49283           0.0                        0.0             400.0       1674.0   \n",
       "...             ...                        ...               ...          ...   \n",
       "456238          0.0                        0.0              93.0        389.0   \n",
       "227387          0.0                        0.0             571.0       2389.0   \n",
       "53775           0.0                        0.0             341.0       1427.0   \n",
       "371169          2.0                        0.0             533.0       2230.0   \n",
       "177986          2.0                        0.0             221.0        925.0   \n",
       "\n",
       "0       fat_100g  saturated-fat_100g  trans-fat_100g  cholesterol_100g  \\\n",
       "9373       32.14               17.86             0.0             0.107   \n",
       "254525      0.00                0.00             0.0             0.000   \n",
       "32228       1.75                0.00             0.0             0.000   \n",
       "10223      23.08                7.69             0.0             0.085   \n",
       "49283       8.75                1.25             0.0             0.000   \n",
       "...          ...                 ...             ...               ...   \n",
       "456238      2.00                1.00             0.0             0.010   \n",
       "227387     42.86               25.00             0.0             0.125   \n",
       "53775      25.88                9.41             0.0             0.082   \n",
       "371169     24.44               15.56             0.0             0.067   \n",
       "177986     11.43                8.57             0.0             0.040   \n",
       "\n",
       "0       carbohydrates_100g  sugars_100g  fiber_100g  proteins_100g  \\\n",
       "9373                  3.57         0.00         0.0          25.00   \n",
       "254525               23.53        17.65         0.0           0.00   \n",
       "32228                50.88         1.75         1.8           8.77   \n",
       "10223                 6.15         4.62         0.0          18.46   \n",
       "49283                60.00         0.00        15.0          17.50   \n",
       "...                    ...          ...         ...            ...   \n",
       "456238               10.00         6.67         0.0          10.00   \n",
       "227387               32.14         0.00         0.0          21.43   \n",
       "53775                 3.53         2.35         0.0          21.18   \n",
       "371169               77.78        31.11         2.2           2.22   \n",
       "177986               25.71        20.00         0.0           4.29   \n",
       "\n",
       "0       sodium_100g  vitamin-a_100g  vitamin-c_100g  calcium_100g  iron_100g  \\\n",
       "9373          0.643        0.000321          0.0000         0.714    0.00000   \n",
       "254525        0.529        0.000000          0.0071         0.000    0.00000   \n",
       "32228         0.456        0.000000          0.0000         0.053    0.00298   \n",
       "10223         1.031        0.000000          0.0018         0.000    0.00166   \n",
       "49283         0.000        0.000000          0.0000         0.100    0.00900   \n",
       "...             ...             ...             ...           ...        ...   \n",
       "456238        0.040        0.000020          0.0000         0.100    0.00000   \n",
       "227387        0.929        0.000429          0.0000         0.357    0.00257   \n",
       "53775         0.906        0.000000          0.0000         0.047    0.00085   \n",
       "371169        0.200        0.000133          0.0000         0.000    0.00160   \n",
       "177986        0.037        0.000129          0.0000         0.129    0.00129   \n",
       "\n",
       "0       nutrition-score-fr_100g  \n",
       "9373                       16.0  \n",
       "254525                      9.0  \n",
       "32228                       2.0  \n",
       "10223                      21.0  \n",
       "49283                      -5.0  \n",
       "...                         ...  \n",
       "456238                     -3.0  \n",
       "227387                     27.0  \n",
       "53775                      23.0  \n",
       "371169                     23.0  \n",
       "177986                     14.0  \n",
       "\n",
       "[2731 rows x 18 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsetX = X.dropna(axis = 0)\n",
    "subsetX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      nan,       nan, 2.200e+02, ...,       nan,       nan,\n",
       "        1.100e+01],\n",
       "       [2.000e+00, 0.000e+00, 3.570e+02, ..., 1.800e-02, 3.214e-02,\n",
       "        8.000e+00],\n",
       "       [6.000e+00, 0.000e+00,       nan, ...,       nan,       nan,\n",
       "        1.400e+01],\n",
       "       ...,\n",
       "       [0.000e+00, 0.000e+00, 4.160e+02, ...,       nan,       nan,\n",
       "        1.700e+01],\n",
       "       [      nan,       nan, 5.030e+02, ...,       nan,       nan,\n",
       "        2.800e+01],\n",
       "       [0.000e+00, 0.000e+00, 3.500e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        3.000e+00]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.000000e-01, 0.000000e+00, 2.200000e+02, ..., 1.365000e-01,\n",
       "        1.405000e-03, 1.100000e+01],\n",
       "       [2.000000e+00, 0.000000e+00, 3.570000e+02, ..., 1.800000e-02,\n",
       "        3.214000e-02, 8.000000e+00],\n",
       "       [6.000000e+00, 0.000000e+00, 3.465000e+02, ..., 0.000000e+00,\n",
       "        0.000000e+00, 1.400000e+01],\n",
       "       ...,\n",
       "       [0.000000e+00, 0.000000e+00, 4.160000e+02, ..., 3.339965e-01,\n",
       "        0.000000e+00, 1.700000e+01],\n",
       "       [3.000000e+00, 0.000000e+00, 5.030000e+02, ..., 1.800000e-02,\n",
       "        1.645000e-03, 2.800000e+01],\n",
       "       [0.000000e+00, 0.000000e+00, 3.500000e+01, ..., 0.000000e+00,\n",
       "        0.000000e+00, 3.000000e+00]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm2(x,y):\n",
    "    return sum((x - y)**2)\n",
    "\n",
    "def r2score(pred, target):\n",
    "    index_missing = isnan(tar)\n",
    "    return 1 - norm2(pred, target) / norm2(target, np.mean(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 My version of it : \n",
    "\n",
    "The methodology is the following. For each column : \n",
    "1. I need to separate the index with nan (that is the one I want to infer) from the rest.\n",
    "2. Then I need to separate a train and test sample, and standardize the X data. \n",
    "3. Then compute a Cross Validation to set the better `n_neighbors` parameter (that is the number of neighbors)\n",
    "4. I use this best fitted param to train my model on X[y==NaN] and predict the corresponding missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection \n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "\n",
    "colname = \"nutrition-score-fr_100g\"\n",
    "\n",
    "##\n",
    "## 1. SEPARATE INDEX WITH AND WITHOUT NANs IN y : \n",
    "## \n",
    "index_without_nans_y = ~data[colname].isna()\n",
    "y = data.loc[index_without_nans_y, colname]\n",
    "X = data.loc[index_without_nans_y, np.setdiff1d(data.columns.intersection(float_var).values,[colname])]\n",
    "\n",
    "##\n",
    "## 2. SPLIT SAMPLE TRAIN-TEST AND STANDARD : \n",
    "## \n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "my_normalizer = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = pd.DataFrame(my_normalizer.transform(X_train), index = X_train.index, columns = X_train.columns)\n",
    "X_test_std = pd.DataFrame(my_normalizer.transform(X_test), index = X_test.index, columns = X_test.columns)\n",
    "\n",
    "##\n",
    "## 3. COMPUTE CV AND EXTRACT BEST PARAM\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additives_n</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>cholesterol_100g</th>\n",
       "      <th>energy-kcal_100g</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>ingredients_from_palm_oil</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>trans-fat_100g</th>\n",
       "      <th>vitamin-a_100g</th>\n",
       "      <th>vitamin-c_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404293</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.22</td>\n",
       "      <td>0.000</td>\n",
       "      <td>351.0</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00270</td>\n",
       "      <td>12.16</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.257</td>\n",
       "      <td>16.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786270</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.148</td>\n",
       "      <td>2.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726441</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.440</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520866</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>444.0</td>\n",
       "      <td>1858.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.60</td>\n",
       "      <td>0.092</td>\n",
       "      <td>46.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72273</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.35</td>\n",
       "      <td>0.000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00057</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.714</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694789</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.0</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.90</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502349</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658953</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>11.20</td>\n",
       "      <td>15.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.00</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.472</td>\n",
       "      <td>3.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423404</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>25.97</td>\n",
       "      <td>0.006</td>\n",
       "      <td>195.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>6.49</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>9.09</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.162</td>\n",
       "      <td>20.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839738</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>412.0</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.140</td>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0        additives_n  calcium_100g  carbohydrates_100g  cholesterol_100g  \\\n",
       "404293           1.0           NaN               66.22             0.000   \n",
       "786270           3.0           NaN               11.00               NaN   \n",
       "726441           0.0           NaN                3.00               NaN   \n",
       "1520866          1.0           NaN               56.00               NaN   \n",
       "72273            1.0          0.00                6.35             0.000   \n",
       "...              ...           ...                 ...               ...   \n",
       "694789           NaN           NaN                0.20               NaN   \n",
       "1502349          NaN           NaN                0.30               NaN   \n",
       "1658953          NaN           NaN               18.70               NaN   \n",
       "423404           3.0          0.13               25.97             0.006   \n",
       "839738           NaN           NaN               68.00               NaN   \n",
       "\n",
       "0        energy-kcal_100g  energy_100g  fat_100g  fiber_100g  \\\n",
       "404293              351.0       1469.0      4.73         8.1   \n",
       "786270               99.0        414.0      4.10         1.4   \n",
       "726441              160.0        665.0     12.00         NaN   \n",
       "1520866             444.0       1858.0     18.00         NaN   \n",
       "72273                48.0        201.0      1.59         1.6   \n",
       "...                   ...          ...       ...         ...   \n",
       "694789              314.0       1314.0     26.00         0.0   \n",
       "1502349             195.0        816.0     10.00         NaN   \n",
       "1658953             360.0       1506.0     11.20        15.5   \n",
       "423404              195.0        816.0      6.49         1.3   \n",
       "839738              412.0       1724.0     13.00         NaN   \n",
       "\n",
       "0        ingredients_from_palm_oil  iron_100g  proteins_100g  \\\n",
       "404293                         0.0    0.00270          12.16   \n",
       "786270                         0.0        NaN           3.70   \n",
       "726441                         0.0        NaN          10.00   \n",
       "1520866                        0.0        NaN          13.00   \n",
       "72273                          0.0    0.00057           1.59   \n",
       "...                            ...        ...            ...   \n",
       "694789                         NaN        NaN          19.90   \n",
       "1502349                        NaN        NaN          26.00   \n",
       "1658953                        NaN        NaN          42.00   \n",
       "423404                         0.0    0.00140           9.09   \n",
       "839738                         NaN        NaN           7.00   \n",
       "\n",
       "0        saturated-fat_100g  sodium_100g  sugars_100g  trans-fat_100g  \\\n",
       "404293                 0.68        0.257        16.22             0.0   \n",
       "786270                 2.90        0.148         2.20             NaN   \n",
       "726441                 8.00        0.440         3.00             NaN   \n",
       "1520866               10.60        0.092        46.00             NaN   \n",
       "72273                  0.00        0.714         3.17             0.0   \n",
       "...                     ...          ...          ...             ...   \n",
       "694789                 8.20        0.640         0.20             NaN   \n",
       "1502349                2.00        5.600         0.00             NaN   \n",
       "1658953                5.70        0.472         3.90             NaN   \n",
       "423404                 2.60        0.162        20.78             0.0   \n",
       "839738                 2.80        0.140        30.00             NaN   \n",
       "\n",
       "0        vitamin-a_100g  vitamin-c_100g  \n",
       "404293              NaN             NaN  \n",
       "786270              NaN             NaN  \n",
       "726441              NaN             NaN  \n",
       "1520866             NaN             NaN  \n",
       "72273          0.000095          0.0429  \n",
       "...                 ...             ...  \n",
       "694789              NaN             NaN  \n",
       "1502349             NaN             NaN  \n",
       "1658953             NaN             NaN  \n",
       "423404         0.000000          0.0000  \n",
       "839738              NaN             NaN  \n",
       "\n",
       "[8000 rows x 17 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\", line 190, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 363, in _fit\n",
      "    X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\", line 433, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 814, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 663, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 103, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/clairegayral/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-f15a822136ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m CV_reg = model_selection.GridSearchCV(neighbors.KNeighborsRegressor(),\n\u001b[1;32m      3\u001b[0m                                       param_grid, cv=5)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mCV_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnearest\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n\u001b[0m\u001b[1;32m    364\u001b[0m                                            multi_output=True)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.env_python/openclassroom/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_neighbors\" : np.arange(1,10,1)}\n",
    "CV_reg = model_selection.GridSearchCV(neighbors.KNeighborsRegressor(),\n",
    "                                      param_grid, cv=5)\n",
    "CV_reg.fit(X_train_std, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3. Linear Regression inference :  \n",
    "\n",
    "Aware of the risk of overfitting, I wanted to use the Linear Regression to impute these missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ce qu'il resterait à faire pour améliorer le notebook :** \n",
    "\n",
    "* appeler les données via l'API json serait bien plus classe, et ça me plairait d'apprendre à faire ce genre de choses.\n",
    "* traiter des variables textes (complètement laissées à l'abandon).\n",
    "* écrire une classe pour le traitement de ce jeu de données, avec une partie prétraitement, et une partie analyse qui irait avec le notebook suivant.\n",
    "* dans l'imputation, faire un post-traitement pour rendre entier les valeurs manquantes dans les colonnes où il faudrait (comme dans la colonne \"n_additives\"). Pour le moment, disons que l'on peut vivre avec des flottants + essayer la méthode d'imputation moyenne par cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openclassroom",
   "language": "python",
   "name": "openclassroom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
